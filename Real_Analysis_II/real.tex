
\documentclass[15pt,a4paper]{book}

\usepackage{amsmath, amsthm, amssymb} 
\usepackage{graphicx} % For including graphics
\usepackage{hyperref} % For clickable links
\usepackage{bookmark} % Better control over bookmarks
\usepackage{geometry} % Customize page layout
\usepackage{xcolor} % Colors for text and graphics
\usepackage{enumitem} % Customizable lists
\usepackage{fancyhdr} % Header and footer
\usepackage{titlesec} % Custom section/chapter titles
\usepackage[toc,page]{appendix} % For the appendix
\usepackage{longtable} % For tables spanning multiple pages
\usepackage{mathrsfs} % For script fonts in math mode
\usepackage{tocloft} % Custom table of contents
\usepackage{datetime2} % For dates
\usepackage{caption} % For better control over captions
\usepackage{float} % Fine control over figure/table placement
\usepackage{imakeidx} % For index

% Custom Theorem Styles
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

\renewcommand{\cftchapfont}{\normalfont} % Remove bold for chapter names
\renewcommand{\cftchappagefont}{\normalfont} % Remove bold for chapter page numbers
\renewcommand{\qedsymbol}{$\blacksquare$}
\newcommand{\eax}[1]{\emph{#1}\index{#1}} % Macro for emphasis and index
\newcommand{\abs}[1]{\left| #1 \right|} % Absolute value
\newcommand{\N}{\mathbb{N}} % Natural Numbers
\newcommand{\R}{\mathbb{R}} % Real numbers
\newcommand{\Z}{\mathbb{Z}} % Integers
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\osc}{\text{osc}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}


% Custom Notation List Environment
\newlist{notationlist}{description}{1}
\setlist[notationlist]{font=\bfseries,labelsep=1em}

% Geometry Settings
\geometry{
    top=2.5cm,
    bottom=2.5cm,
    left=2.5cm,
    right=2.5cm,
}

% Hyperref Colors
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=cyan,
    citecolor=red
}

\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{#1}}

% Custom Headers
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark} % Chapter name on top left
\fancyhead[R]{\rightmark}  % section name on top right
\fancyfoot[C]{\thepage}

\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Making index
\makeindex[intoc]

% Title Formatting
\titleformat{\chapter}[display]
  {\normalfont\Large\bfseries \centering}
  {\chaptername\ \thechapter}{20pt}{\Huge \centering}

\titlespacing*{\chapter}{0pt}{20pt}{100pt}

\begin{document}

\pagestyle{empty}

\begin{titlepage}
    \begin{center}
    \vspace*{\fill}
    % Title in all caps
    {\Huge \textbf{\MakeUppercase{Real Analysis II}}\par}

    \vspace{0.5cm} % Adjust vertical spacing between title and subtitle
    % Subtitle in normal text, slightly enlarged
    {\Large Jaydeb Sarkar, notes by Ramdas Singh\par}

    \vspace{0.5cm} % Additional spacing before the author
    % Author information
    {\large Second Semester\par}
    \vspace*{\fill}
    \end{center}
\end{titlepage}

\clearpage

\pagenumbering{roman}

\chapter*{List of Symbols}
\begin{notationlist}
    \item $[a,b]$, the set of all real numbers $x$ such that $a \leq x \leq b$.
    \item $\mathbb{N} = \{1,2,\ldots\}$, the set of all natural numbers.
    \item $\mathbb{Z}_{+}$, defined as $\mathbb{N} \cup \{0\}$.
    \item $\mathcal{B}[a,b]$, the set of all boundary functions defined as $\{f:[a,b] \to \mathbb{R}\}$. It is a vector space (also an algebra) over $\mathbb{R}$.
    \item $\mathcal{P}[a,b]$, the set of all partitions of the set $[a,b]$.
    \item $I_{j}$, the $j^{\text{th}}$ subinterval of $[a,b]$, controlled by a partition set.
    \item $L(f,P)$, the lower Riemann sum for a function $f$ and partition $P$.
    \item $U(f,P)$, the upper Riemann sum for a function $f$ and partition $P$.
    \item $\int_{\underline{a}}^{b} f$, the lower Riemann integration for a function $f$.
    \item $\int_{a}^{\overline{b}} f$, the upper Riemann integration for a function $f$.
    \item $\mathcal{R}[a,b]$, the set of all Riemann integrable functions over the set $[a,b]$.
    \item $\cC[a,b]$, the set of all continuous functions over the set $[a,b]$.
    \item $\{a_{n}\}_{n \geq 1}$, a sequence of real numbers.
    \item $T_{P}$, a tag set for the partition $P$.
    \item $\cD$, the set of all differentiable functions.
    \item $\cF (\R)$, the set of all real functions.
\end{notationlist}

\newpage
\setcounter{tocdepth}{2}
\tableofcontents

\newpage
\pagenumbering{arabic}
\pagestyle{fancy}


%%-------------------------------------------------------------------------------------------------

\chapter{THE RIEMANN INTEGRAL}

\section{On The Path of Definitions}

\textit{January 6th.}

\begin{definition}
    A \eax{partition} of $[a,b]$ are all the points $a=x_{0}<x_{1}<\ldots<x_{n} = b$. These points within are termed \eax{nodes}, and there are $n-1$ of them. The set $I_{j}$, defined by $[x_{j-1},x_{j}]$ denotes the $j^{\text{th}}$ subinterval.
\end{definition}

\begin{definition}
    If $I = (a,b), [a,b], (a,b], [b,a)$, then the \eax{length of the interval} $I$ is denoted by $b-a$.
\end{definition}

Denote by $\mathcal{P}[a,b]$, the set of all partition sets of $[a,b]$. For $P \in \mathcal{P}[a,b]$, with $n-1$ nodes, the length of $[a,b]$ will be $\abs{[a,b]} = \sum_{j=1}^{n} I_{j}$. We also note that for all $P, \tilde{P} \in \mathcal{P}[a,b]$, $P \cup \tilde{P} \in \mathcal{P}[a,b]$. Note that here we consider $n$ to be finite.

\begin{example}
    The set $\{\frac{1}{n}\}_{n \geq 1} \cup \{0\}$ does not belong to the set of all partitions of the unit interval, $\mathcal{P}[0,1]$.
\end{example}

Let $f \in \mathcal{B}[a,b]$, and $P \in \mathcal{P}[a,b]$. Suppose $P$ has the nodes $a = x_{0} < x_{1} < \ldots < x_{n} = b$. For all $j = 1, \ldots n$, define $m_{j} = \inf_{x \in I_{j}} f(x)$ and $M_{j} = \sup_{x \in I_{j}} f(x)$. Finally, denote by $m$ the value of $\inf_{x \in [a,b]} f(x)$ and $M$ to be $\sup_{x \in [a,b]} f(x)$. These are all real values.

Note that for all valid $j$, $m \leq m_{j} \leq M_{j} \leq M$ always holds. This must mean that
\begin{align}
    m \abs{I_{j}} &\leq m_{j} \abs{I_{j}} \leq M_{j} \abs{I_{j}} \leq M \abs{I_{j}} \notag \\
    m(b-a) &\leq \sum_{j=1}^{n} m_{j} \abs{I_{j}} \leq \sum_{j=1}^{n} M_{j} \abs{I_{j}} \leq M(b-a).
\end{align}

\begin{definition}
    Let $f \in \mathcal{B}[a,b]$. For $P$ $(a = x_{0}, x_{1}, \ldots, x_{n} = b)$ $\in \mathcal{P}[a,b]$, the \eax{lower Riemann sum} and the \eax{upper Riemann sum} are defined as
    \begin{equation}
        L(f,P) = \sum_{j=1}^{n} m_{j} \abs{I_{j}} \text{ and } U(f,P) = \sum_{j=1}^{n} M_{j} \abs{I_{j}},
    \end{equation}
    respectively. Thus, $m(b-a) \leq L(f,P) \leq U(f,P) \leq M(b-a)$ $\forall$ $P \in \mathcal{P}[a,b]$.
\end{definition}

\begin{remark}
    Clearly, $L(f,P), U(f,P) \in \mathbb{R}$ for all paritions $P \in \mathcal{P}[a,b]$ and all boundary functions $f \in \mathcal{B}[a,b]$. In fact, $L(f,P), U(f,P) \in [m(b-a),M(b-a)]$.
\end{remark}

\begin{definition}
    For $f \in \mathcal{B}[a,b]$, the \eax{lower Riemann integration} is defined as
    \begin{equation}
        \int_{\underline{a}}^{b} f = \sup\{L(f,P) | P \in \mathcal{P}[a,b]\}.
    \end{equation}
    Subsequently, the \eax{upper Riemann integration} is defined as
    \begin{equation}
        \int_{a}^{\overline{b}} f = \inf\{U(f,P) | P \in \mathcal{P}[a,b]\}.
    \end{equation}
\end{definition}
\begin{remark}
    Note that both $\int_{\underline{a}}^{b} f$ and $\int_{a}^{\overline{b}} f$ belong to the set $[m(b-a),M(b-a)]$.
\end{remark}

\begin{definition}
    A function $f \in \mathcal{B}[a,b]$ is \eax{Riemann integrable} if the lower and the upper Riemann integration are equal, that is, $\int_{\underline{a}}^{b} f = \int_{a}^{\overline{b}} f$. We denote this value by $\int_{a}^{b} f$, and call it the integration of $f$ over $[a,b]$. We then say that $f \in \mathcal{R}[a,b]$.
\end{definition}
\textit{January 8th.}
\begin{example}
    Note that $\cR [a,b] \subseteq \cB [a,b]$. In fact, it is a proper subset; for there exists the \eax{Dirichlet function} $f:[0,1] \to \R$ defined by
    \begin{equation}
        f(x) = \begin{cases}
            1 &\text{ if } x \in \mathbb{Q} \cap [0,1],\\
            0 &\text{ if otherwise.}
        \end{cases}
    \end{equation}
    Clearly, $f$ is a boundary function but not a continuous one. Now pick a partition $P$ with $x_{0}=0<x_{1}<\ldots<x_{n}=1$. Now, $m_{j}=0 \; \forall \; \implies L(f,P) = 0 \; \forall \; P \implies \int_{\underline{0}}^{1} f = 0$. If we consider that $M_{j}$ is always 1, we get $\int_{0}^{\overline{1}} f = 1$. $f$ does not belong to the set of Riemann integrable functions.
\end{example}
\begin{example}
    We show that $\cR [a,b]$ is not empty. Simply pick $f:[a,b] \to \R$ defined by $f(x) = c$ for all valid $x$. For every partition of this interval, we $m_{j} = M_{j} = c$ for all $j$. Finally, after computing the lower Riemann and upper Riemann sums, we get $\int_{\underline{a}}^{b} f = \int_{a}^{\overline{b}} f = c(b-a)$.
\end{example}
\begin{example}
    There exists a function $f \in \cB [a,b]$ such that $\abs{f} \in \cR [a,b]$ but $f \notin \cR [a,b]$. Indeed, simply pick a modification of the Dirichlet function defined as
    \begin{equation}
        f(x) = \begin{cases}
            -1 &\text{ if } x \in \mathbb{Q} \cap [a,b],\\
            1 &\text{ if otherwise.}
        \end{cases}
    \end{equation}
\end{example}

\begin{definition}
    Let $P, \tilde{P} \in \cP [a,b]$. We say $\tilde{P} \supset P$, or $\tilde{P}$ is a \eax{refinement} of $P$ if the nodes of $P$ are a subset of the nodes of $\tilde{P}$.
\end{definition}
\begin{example}
    For all $P,\tilde{P} \in \cP [a,b]$, we have $P \cup \tilde{P} \supset P, \tilde{P}$.
\end{example}
\begin{proposition}
    Let $f \in \cB [a,b]$, and $P, \tilde{P} \in cP [a,b]$. Suppose $\tilde{P} \supset P$. Then
    \begin{equation}
        L(f,P) \leq L(f,\tilde{P}) \leq U(f,\tilde{P}) \leq U(f,P).
    \end{equation}
\end{proposition}
\begin{proof}
    Note that it is sufficient to prove the first inequality; the second one is already true and the third one is analagous to the first one. Set $\tilde{P} = P \cup \{\tilde{x}\}$ with $\tilde{x} \notin P$, and set $P$ as $a = x_{0} < x_{1} < \ldots < x_{n} = b$. As $\tilde{x}$ is not part of $P$, there must exist some $j \in \{1, \ldots, n\}$ such that $\tilde{x} \in (x_{j-1},x_{j})$.

    For this $j$, let $\tilde{m}_{j-1} = \inf_{[x_{j-1},\tilde{x}]} f$ and let $\tilde{m}_{j} = \inf_{[\tilde{x},x_{j}]} f$. Therefore, we shall have
    \begin{align}
        L(f,\tilde{P}) - L(f,P) &= \tilde{m}_{j-1}(\tilde{x}-x_{j-1}) + \tilde{m}_{j}(x_{j}-\tilde{x}) - m_{j}(x_{j}-x_{j-1}) \notag \\
        &= \tilde{m}_{j-1}(\tilde{x}-x_{j-1}) + \tilde{m}_{j}(x_{j}-\tilde{x}) - m_{j}(x_{j}-\tilde{x}) - m_{j}(\tilde{x}-x_{j-1}) \notag \\
        &= (\tilde{m}_{j}-m_{j})(x_{j}-\tilde{x}) + (\tilde{m}_{j-1} - m_{j})(\tilde{x}-x_{j-1}) \geq 0 \notag \\
        \implies L(f,\tilde{P}) - L(f,P) &\geq 0.
    \end{align}
    Induction may now be applied to make any refinement $\tilde{P}$ of $P$. A similar logic applies to the upper Riemann sums.
\end{proof}
\begin{corollary}
    Let $f \in \cB [a,b]$. Then, for all $P,Q \in \cP [a,b]$, $L(f,P) \leq U(f,Q)$.
\end{corollary}
\begin{proof}
    Choose $R = P \cup Q$ to be a refinement of both $P$ and $Q$. Applying the previous proposition, we simply get $L(f,P) \leq L(f,R) \leq U(f,R) \leq U(f,Q)$.
\end{proof}
\begin{corollary}
    For all $f \in \cB [a,b]$, $\int_{\underline{a}}^{b} f \leq \int_{a}^{\overline{b}} f$ is always true.
\end{corollary}
\begin{proof}
    The lower Riemann intergral is the supremum of all the lower Riemann sums, so it must be the lowest upper bound, and, thus, has to be lesser than the upper Riemann sums. Similarly, the upper Riemann integral is greater than the lower Riemann sums. Consequently, we get the desired inequality.
\end{proof}
\section{Classification and Computation}
We now discuss the classification of Riemann integrable functions, and the computation of the Riemann integral.
\begin{theorem}
    Let $f \in \cB [a,b]$. Then, for $f$ to be Riemann intergrable, the only neccessary and sufficient condition is $\int_{\underline{a}}^{b} f \geq \int_{a}^{\overline{b}} f$.
\end{theorem}
\begin{proof}
    If the condition is satisfied, then we must conclude that the Riemann integrals have to be equal. The converse follows the opposite argument.
\end{proof}
\begin{theorem}
    Let $f \in \cB [a,b]$. Then $f \in \cR [a,b]$ if and only if for every $\varepsilon > 0$, there exists a $P \in \cP [a,b]$ such that $U(f,P) - L(f,P) < \varepsilon$.
\end{theorem}
\begin{proof}
    We first prove the converse; assume that for every $\varepsilon > 0$, there exists a $P$ satisfying $U(f,P) - L(f,P) < \varepsilon$. Now,
    \begin{align}
        L(f,P) \leq \underline{\int} f \leq \overline{\int} f \leq U(f,P) < \varepsilon + L(f,P) \leq \varepsilon + \underline{\int} f \notag \\
        \implies \overline{\int} f - \underline{\int} f < \varepsilon \; \forall \; \varepsilon < 0\\
        \implies \overline{\int} f = \underline{\int} f.
    \end{align}
    To show that every Riemann integrable function satisfies this property, let $f \in \cR [a,b]$ and $\varepsilon > 0$. The Riemann integrals are a supremum and an infimum, so there must exist a $P_{1} \in \cP [a,b]$ such that $L(f,P_{1}) > \int f - \frac{\varepsilon}{2}$ and a $P_{2} \in \cP [a,b]$ such that $U(f,P_{1}) < \int f + \frac{\varepsilon}{2}$. Now choose $P$ to be $P_{1} \cup P_{2}$, a refinement of both $P_{1}$ and $P_{2}$. Therefore,
    \begin{align}
        U(f,P) \leq U(f,P_{2}) < \int f + \frac{\varepsilon}{2} < (L(f,P_{1}) + \frac{\varepsilon}{2}) + \frac{\varepsilon}{2} \leq L(f,P) + \varepsilon \notag \\
        \implies U(f,P) - L(f,P) < \varepsilon.
    \end{align}
\end{proof}

\begin{definition}
    Let $P$ be a partition with $a=x_{0} < x_{1} < \ldots < x_{n} = b$. We define the \eax{norm} of $P$, or the \eax{mesh} of $P$, as $\norm{P} = \max_{j}\{x_{j}-x_{j-1}\}$.
\end{definition}

\begin{theorem}[\eax{Darboux's theorem}]
    Let $f \in \cB [a,b]$. Then $f \in \cR [a,b]$ if and only if for every $\varepsilon > 0$, there exists a $\delta > 0$ such that $U(f,P)-L(f,P) < \varepsilon$ for all $P \in \cP [a,b]$ with $\norm{P} < \delta$. 
\end{theorem}
\begin{remark}
    To prove this, we define $\eta: \cP [a,b] \to \R_{\geq 0}$ by $\eta(P) = U(f,P) - L(f,P)$ for all $P \in \cP [a,b]$.
\end{remark}
\begin{proof}
    The proof of the converse is trivial and follows the same reasoning as before. To show that every Riemann integrable function satisfies this property, let $f \in \cR [a,b]$ and $\varepsilon > 0$. There exists a $\tilde{P} \in \cP [a,b]$ such that $U(f,\tilde{P}) - L(f,\tilde{P}) < \frac{\varepsilon}{2}$. Denote the number of nodes in $\tilde{P}$ by $p$, and set $\delta = \frac{\varepsilon}{8pM}$, where $M$ is the supremum of $f$ over $[a,b]$. Pick $P \in \cP [a,b]$ and assume that $\norm{P} < \delta$. Now set $\hat{P} = P \cup \tilde{P}$; $\hat{P}$ has at most $p$ points that are not in $P$.

    For now, assume that $p = 1$. Then, $\tilde{P} = P \cup \{\tilde{x}\}$ with $\tilde{x} \notin P$. Thus, with variables defined as before,
    \begin{equation}
        L(f,\hat{P}) - L(f,P) = (\tilde{m}_{j}-m_{j})(x_{j}-\tilde{x}) + (\tilde{m}_{j-1} - m_{j})(\tilde{x}-x_{j-1}).
    \end{equation}
    Notice that $(\tilde{m}_{j}-m_{j}), (\tilde{m}_{j-1} - m_{j}) < 2M$ and $(x_{j}-\tilde{x}), (\tilde{x}-x_{j-1}) < \delta$. In fact, in general, for an arbitrary $p$, we have
    \begin{equation}
        L(f,\hat{P}) - L(f,P) < 4pM\delta = \frac{\varepsilon}{2}.
    \end{equation}
    A similar story unfolds for the upper sums,
    \begin{equation}
        U(f,P) - U(f, \hat{P}) < \frac{\varepsilon}{2}.
    \end{equation}
    Together, the equations combine to form
    \begin{align}
        U(f,P) - L(f,P) < \varepsilon + U(f,\hat{P})-L(f,\hat{P}) < \varepsilon + U(f,\tilde{P})-L(f,\tilde{P}) < 2\varepsilon.
    \end{align}
\end{proof}
\textit{January 13th.}\\
We now wish to answer two questions; which elements reside in the set $\cR[a,b]$, and the value of the Riemann integral $\int_{a}^{b} f$ for some $f \in \cR[a,b]$.

Let us first wonder whether $\cC[a,b]$, the set of continuous functions, is a subset of $\cR[a,b]$. In fact, this is true.

\begin{theorem}
    $\cC[a,b] \subseteq \cR[a,b]$.
\end{theorem}
\begin{proof}
    Fix $f \in \cC[a,b]$; thus, $f:[a,b] \to \R$ is also uniformly continuous. For all $\varepsilon > 0$, there eixsts $\delta > 0$ such that
    \begin{equation}
        \abs{f(x)-f(y)} < \frac{\varepsilon}{b-a} \text{ for all } \abs{x-y} < \delta.
    \end{equation}
    Pick $P \in \cP[a,b]$ such that $\norm{P} < \delta$, and fix such a $P : a = x_{0} < x_{1} < \ldots < x_{n} = b$. Thus,
    \begin{align}
        U(f,P) - L(f,P) &= \sum_{j=1}^{n} (M_{j}-m_{j})\abs{I_{j}}.
    \end{align}
    Now, $f|_{I_{j}} : I_{j} \to \R$ is a continuous function for all valid $j$. Therefore, there exist $\eta_{j}, \zeta_{j} \in I_{j}$ such that $f(\eta_{j}) = M_{j}$ and $f(\zeta_{j}) = m_{j}$. $M_{j}-m_{j}$ can be rewritten as $f(\eta_{j}) - f(\zeta_{j})$. As $\abs{\eta_{j}-\zeta_{j}} < \delta$, it follows that
    \begin{align}
        M_{j}-m_{j} &< \frac{\varepsilon}{b-a} \text{ for all } j \\
        \implies (M_{j}-m_{j})\abs{I_{j}} &< \frac{\varepsilon}{b-a} \abs{I_{j}} \notag \\
        \implies \sum_{j=1}^{n} (M_{j}-m_{j}) \abs{I_{j}} &< \varepsilon.
    \end{align}
    By Darboux's theorem, $f$ is Riemann integrable.
\end{proof}
We now wish to compute $\int_{a}^{b} f$. Our first attempt at this is the following theorem.
\begin{theorem}
    Let $f \in \cB[a,b]$. Then $f \in \cR[a,b]$ if and only if there exists a sequence $\{P_{n}\}_{n \geq 1} \subseteq \cP[a,b]$ such that
    \begin{equation}
        \lim_{n \to \infty} U(f,P_{n}) - L(f,P_{n}) = 0.
    \end{equation}
    Moreover, in this case,
    \begin{equation}
        \int_{a}^{b} f = \lim_{n \to \infty} U(f,P_{n}) = \lim_{n \to \infty} L(f,P_{n}).
    \end{equation}
\end{theorem}
\begin{proof}
    Let us first assume that $f$ is Riemann integrable. Thus, for $\varepsilon = \frac{1}{n}$, there exists $P_{n} \in \cP[a,b]$ such that
    \begin{equation}
        0 \leq U(f,P) - L(f,P) < \frac{1}{n}
        \implies U(f,P) - L(f,P) \to 0.
    \end{equation}
    For the converse, let $\varepsilon > 0$. There exists $N \in \N$ such that
    \begin{equation}
        0 \leq U(f,P_{n}) - L(f,P_{n}) < \varepsilon \text{ for all } n \geq N.
    \end{equation}
    Pick $n$ to be $N$. Thus, $U(f,P_{N}) - L(f,P_{N}) < \varepsilon$ must imply that $f \in \cR[a,b]$.

    Let us now show the computation of the integral. We have
    \begin{align}
        0 \leq U(f,P_{n}) - \overline{\int_{a}^{b}} = U(f,P_{n}) - \underline{\int_{a}^{b}} f \leq U(f,P_{n}) - L(f,P_{n}) &\to 0 \implies \\
        \implies U(f,P_{n}) &\to \int_{a}^{b}f.
    \end{align}
    Similarly,
    \begin{align}
        0 \leq \underline{\int_{a}^{b}} f - L(f,P_{n}) = \int_{a}^{b} f - U(f,P_{n}) + U(f,P_{n}) - L(f,P_{n}) &\to 0 \\
        \implies L(f,P_{n}) &\to \int_{a}^{b} f.
    \end{align}
\end{proof}
\begin{remark}
    Let $f \in \cB[a,b]$, and let $\{P_{n}\}_{n \geq 1} \subseteq \cP[a,b]$. If $L(f,P_{n}) \to \lambda$ and if $U(f,P_{n}) \to \lambda$. We then must have $f \in \cR[a,b]$ and $\int_{a}^{b} = \lambda$. This is reminiscent of Newton's method of integration.
\end{remark}
\begin{example}
    Let us compute $\int_{0}^{1}f$ where $f(x) = x^{2}$ on $[0,1]$. For all $n \in \N$, consider the partitions $P_{n} : 0 = x_{0} < x_{1} = \frac{1}{n} < x_{2} = \frac{2}{n} < \ldots < x_{n} = \frac{n}{n} = 1$. Thus, $I_{j} = \left[ \frac{j-1}{n}, \frac{j}{n} \right] \text{ for all } j = 1, \ldots, n$. We then have $M_{j} = (\frac{j}{n})^{2}$ and $m_{j} = (\frac{j-1}{n})^{2}$. The sums can be computed as
    \begin{align}
        U(f,P_{n}) &= \sum_{j=1}^{n} \frac{1}{n} \cdot \frac{j^{2}}{n^{2}} = \frac{1}{n^{3}} \sum_{j=1}^{n} j^{2} = \frac{(n+1)(2n+1)}{6n^{2}} &\to \frac{1}{3}, \\
        L(f,P_{n}) &= \sum_{j=1}^{n} \frac{1}{n} \cdot \frac{(j-1)^{2}}{n^{2}} = \frac{1}{n^{3}} \sum_{j=1}^{n} (j-1)^{2} = \frac{(n-1)(2n-1)}{6n^{2}} &\to \frac{1}{3}.
    \end{align}
    Both sums converge to $\frac{1}{3}$; $f$ is Riemann integrable and $\int_{0}^{1} f = \frac{1}{3}$.
\end{example}
\begin{example}
    We show that $\cC[a,b]$ is a proper subset of $\cR[a,b]$. Let us consider the function $f:[a,b] \to \R$ defined by
    \begin{equation}
        f(x) = \begin{cases}
        1 &\text{ if } 0 \leq x < \frac{1}{2}, \\
        \frac{1}{2} &\text{ if } x = \frac{1}{2}, \\
        0 &\text{ if } \frac{1}{2} < x \leq 1.
        \end{cases}
    \end{equation}
    Fix $\varepsilon > 0$. Choose the partition $P_{\varepsilon} : 0 < \frac{1}{2}-\varepsilon < \frac{1}{2} + \varepsilon < 1$. We then have $m_{1} = 1 = M_{1}$, $m_{2} = 0 = m_{3}$, and $M_{2} = 1$, $M_{3} = 0$. Therefore, we have
    \begin{equation}
        L(f,P) = \frac{1}{2}-\varepsilon, \; U(f,P) = \frac{1}{2} + \varepsilon.
    \end{equation}
    Finally,
    \begin{equation}
        U(f,P) - L(f,P) = 2\varepsilon < 3\varepsilon.
    \end{equation}
    $f$ is Riemann integrable, but is not a continuous function.
\end{example}
\textit{January 15th.}\\ \\
We now discuss a more refined way of computing the Riemann integral.
\begin{definition}
    Let $P:a=x_{0} < x_{1} < \ldots < x_{n} = b$ be a partition of $[a,b]$. A \eax{tag} of $P$ is a function $T_{P}:\{I_{j}\}_{j=1}^{n} \to [a,b]$ such that $T_{p}(I_{j}) \in I_{j}$ for all $j = 1,2,\ldots,n$. In other words, $T_{p} = \{\zeta_{j}\}_{j=1}^{n}$ such that $\zeta_{j} \in I_{j}$ for all valid $j$.
\end{definition}
\begin{definition}
    Let $f \in \cB[a,b]$, $P \in \cP[a,b]$, and $T_{P}$ be a tag set. The \eax{Riemann sum} of $f$ with respect $(P,T_{P})$ is
    \begin{equation}
        S(f,P) = \sum_{j=1}^{n} f(\zeta_{j})\abs{I_{j}}.
    \end{equation}
\end{definition}
What good is Riemann sum and why the need for defining it? Let us fix $f \in \cB[a,b]$, $P \in \cP[a,b]$, and $T_{P} = \{\zeta_{j}\}_{j=1}^{n}$. We now have $m_{j} \leq f(\zeta_{j}) \leq M_{j}$ for all valid $j$. Multiplying by the subintervals $\abs{I_{j}}$ and summing over all $j$'s gives us
\begin{equation}
    L(f,P) \leq S(f,P) \leq U(f,P)
\end{equation}
for any tag set $T_{P}$. This gives us a better condition as if both the lower and upper sum collapse, then the Riemann sum will give us a value, say $\lambda$, for any tag set $T_{P}$.

What do we hope for? We wish to show that $L(f,P) \to \lambda$ as $\norm{P} \to 0$. Let us write this more formally.
\begin{definition}
    Given $f \in \cB[a,b]$ and $\lambda \to \R$, we say
    \begin{equation}
        \lim_{\norm{P} \to 0} S(f,P) = \lambda
    \end{equation}
    if for every $\varepsilon > 0$, there exists $\delta > 0$ such that
    \begin{equation}
        \abs{S(f,P) - \lambda} < \varepsilon \text{ for all } P \in \cP[a,b] \text{ satisfying } \norm{P} < \delta \text{ for any } T_{P}.
    \end{equation}
\end{definition}
Note that if such $\lambda$ exists, it is unique.
\begin{theorem}
    Let $f \in \cB[a,b]$. Then $f \in \cR[a,b]$ if and only if there exists $\lambda \in \R$ such that $\lim_{\norm{P} \to 0} S(f,P) = \lambda$. Also, in this case, $\int_{a}^{b} f = \lambda$.
\end{theorem}
\begin{proof}
    Assume $f$ is Riemann integrable. Let $\lambda = \int_{a}^{b} f$, For every $\varepsilon > 0$, there exists $\delta > 0$ such that
    \begin{equation*}
        U(f,P) - L(f,P) < \varepsilon \text{ for all } \norm{P} < \delta.
    \end{equation*}
    We know that $L(f,P) \leq S(f,P) \leq U(f,P)$ for all tag sets $T_{P}$. Now,
    \begin{equation}
        L(f,P) \geq U(f,P) - \varepsilon \geq \overline{\int} f - \varepsilon = \lambda - \varepsilon.
    \end{equation}
    Similarly,
    \begin{equation}
        U(f,P) < \varepsilon + L(f,P) \leq \varepsilon + \underline{\int} f = \varepsilon + \lambda.
    \end{equation}
    Thus, we have, for all $P \in \cP[a,b]$ satisfying $\norm{P} < \delta$ and for all $T_{P}$, we have
    \begin{equation*}
        \lambda - \varepsilon < S(f,P) \leq \lambda + \varepsilon \implies \abs{S(f,P) - \lambda} < \varepsilon \implies \lim_{\norm{P} \to 0} S(f,P) = \lambda.
    \end{equation*}
    For the converse, let $\lambda = \lim_{\norm{P} \to 0} S(f,P)$. Then for all $\varepsilon > 0$, there exists $\delta > 0$ such that
    \begin{equation*}
        \abs{S(f,P) - \lambda} < \frac{\varepsilon}{3}
    \end{equation*}
    for all $\abs{P} < \delta$ and for all $T_{P}$. Note that $S(f,P)$ is just $\sum_{j=1}^{n} f(\zeta_{j}) \abs{I_{j}}$. By taking the infimum and supremum of tag sets for a fixed $P$ over their valid intervals, we have
    \begin{equation}
        \lambda-\frac{\varepsilon}{3} < L(f,P) < \lambda + \frac{\varepsilon}{3}, \; \lambda - \frac{\varepsilon}{3} < U(f,P) < \lambda + \frac{\varepsilon}{3}.
    \end{equation}
    Finally, we can now minimize $U(f,P) - L(f,P)$ for Darboux's criteria---
    \begin{equation}
        U(f,P) - L(f,P) < \lambda+\frac{\varepsilon}{3} - \lambda + \frac{\varepsilon}{3} = \frac{2\varepsilon}{3} < \varepsilon \implies f \in \cR[a,b].
    \end{equation}
    Finally, for all $\norm{P} < \delta$, we have
    \begin{equation}
        \lambda - \frac{\varepsilon}{3} < L(f,P) \leq \underline{\int}f = \int f = \overline{\int}f < U(f,P) < \lambda + \frac{\varepsilon}{3} \implies \lambda = \int f.
    \end{equation}
\end{proof}

We are now done with the classification and computation of the Riemann integral.

\begin{theorem}
    Let $f \in \cR[a,b]$ and let $\{P_{n}\} \subseteq \cP[a,b]$ such that $\norm{P_{n}} \to 0$. Then
    \begin{equation}
        \lim_{n \to \infty} S(f,P_{n}) = \int_{a}^{b} f
    \end{equation}
    for all tag sets $T_{P_{n}}$.
\end{theorem}
\begin{proof}
    $f$ is Riemann integrable. For all $\varepsilon > 0$, there exists $\delta > 0$ such that for all $\norm{P} < \delta$, $U(f,P)-L(f,P) < \varepsilon$. There also exists a natural $N$ such that $\norm{P_{n}} < \delta$ for all $n \geq N$. This tells us that $U(f,P_{n})-L(f,P_{n}) < \varepsilon$ for all $n \geq N$. We rewrite this as
    \begin{align}
        U(f,P_{n}) - \int f + \int f - L(f,P_{n}) < \varepsilon \text{ for all } n \geq N.
    \end{align}
    Pairing up the terms on the left, we find that they are non-negative, so each pair individually must be less than $\varepsilon$---
    \begin{equation}
        0 \leq U(f,P_{n}) - \int f < \varepsilon \text{ and } 0 \leq \int f - L(f,P_{n}) < \varepsilon
    \end{equation}
    Using this equation, we can finally write
    \begin{equation}
        \int f - \varepsilon < L(f,P_{n}) \leq S(f,P_{n}) \leq U(f,P_{n}) < \int f + \varepsilon \implies \lim_{n \to \infty} S(f,P_{n}) = \int f.        
    \end{equation}
    Again, this is regardless of the choice of tag sets.
\end{proof}
\section{School Integration Rocks}
Let us now connect to Newton's definition of integration. Pick $f \in \cC[a,b]$. For any $n \in \N$, consider the partition $P_{n} : a = x_{0} < x_{1} < \ldots < x_{n} = b$ such that $x_{j}-x_{j-1} = \frac{b-a}{n}$. This is the standard school partition. Note that $\norm{P_{n}} = \frac{b-a}{n} \to 0$. For all tag sets $\{\zeta_{j}^{(n)}\}$ of $P_{n}$, we find that
\begin{equation}
    \int_{a}^{b} f = \lim_{n \to \infty} \sum_{j=1}^{n} f(\zeta_{j}^{(n)}) \frac{b-a}{n}.
\end{equation}
In school, the tag set was generally chosen as the left endpoints or right endpoints of the subintervals. The left endpoints tag set is
\begin{equation}
    \zeta_{j} = a + \frac{b-a}{n}(j-1).
\end{equation}

\chapter{ANTIDERIVATIVES}
\textit{January 20th.}\\ \\
Let us first summarise; let $f$ be a bounded function on the interval $[a,b]$. Then, the following are equivalent---
\begin{itemize}
    \item $f \in \cR[a,b]$,
    \item For $\varepsilon > 0$, there exists $P \in \cP[a,b]$ such that $U(f,P)-L(f,P) < \varepsilon$,
    \item For $\varepsilon > 0$, there exists $\delta > 0$ such that for all $P \in \cP[a,b]$ satisfying $\norm{P} < \delta$, $U(f,P)-L(f,P) < \varepsilon$,
    \item There exists $\{P_{n}\} \subset \cP[a,b]$ such that $U(f,P_{n})-L(f,P_{n}) \to 0$,
    \item There exists $\{P_{n}\} \subset \cP[a,b]$ such that $\lim_{n \to \infty} U(f,P_{n}) = \lim_{n \to \infty} L(f,P_{n})$,
    \item $\lim_{\norm{P} \to 0} S(f,P) = \lambda$.
\end{itemize}

\section{Spaces and Algebras}
Note that $\cB[a,b]$ is a vector space; a linear combination of two elements in it is also part of this set. If we now define a multiplication of two vectors in it as $(f \cdot g)(x) = f(x) \cdot g(x)$ for $f,g \in \cB[a,b]$, we see that $f \cdot g$ is also a vector in this space. Thus, we have made $\cB[a,b]$ into an algebra.

We now question if $\cR[a,b]$ is an algebra, or even a vector space. We begin by defining $\cI: \cR[a,b] \to \R$ by $\cI (f) = \int_{a}^{b} f$. We can ask the following questions:
\begin{itemize}
    \item whether $\cI$ is linear; $\cI(rf+g) = r\cI(f) + \cI(g)$, for $r \in \R$,
    \item whether $\cI$ is multiplicative; $\cI(f \cdot g) = \cI(f) \cdot \cI(g)$.
\end{itemize}
Other questions can also be asked; is $\cI$ a monotonic function, or even a homomorphism if $\cR[a,b]$ proves to be a vector space.\\

Given $f \in \cB[a,b]$ and $P \in \cP[a,b]$, we have
\begin{equation}
    M_{j} - m_{j} = \sup\{\abs{f(x)-f(y)} : x,y \in I_{j}\}.
\end{equation}
We denote this value by $\osc_{I_{j}} f$, the oscillation of $f$ over $I_{j}$. If we adopt this notation, we would then have
\begin{equation}
    U(f,P) - L(f,P) = \sum_{j=1}^{n} \osc_{I_{j}} f \cdot \abs{I_{j}}.
\end{equation}
\subsection{Results on $\cI$ and $\cR[a,b]$}
Assume that, here, $f,g \in \cR[a,b]$ and $r \in \R$.
\begin{enumerate}
\item Coming back, let us prove that $\cI$ is, in fact, linear.
\begin{proof}
    First, we show that $rf+g$ is Riemann integrable for $f,g \in \cR[a,b]$. For any partition $P \in \cP[a,b]$, we have
    \begin{align}
        S(rf+g,P) &= \sum_{j=1}^{n} (rf+g)(\zeta_{j})\abs{I_{j}} \notag \\
        &= r \sum_{j=1}^{n} f(\zeta_{j})\abs{I_{j}} + \sum_{j=1}^{n} g(\zeta_{j}) \abs{I_{h}} = rS(f,P)+S(g,P).
    \end{align}
    This result is regardless of choice of tag set $T_{P}$. Thus, $rf+g \in \cR[a,b]$. Now, we show the linearity of $\cI$.
    \begin{align}
        \abs{S(rf+g,P) -r\int f - \int g} &= \abs{r(S(f,P)-\int f) + (S(g,P) - \int g)} \leq \abs{r}\abs{S(f,P)-\int f} + \abs{S(g,P)- \int g} \\
        \implies S(rf+g,P) &\to r \int f + \int g \text{ as } \norm{P} \to 0.
    \end{align}
\end{proof}
\item We now show that $f \cdot g \in \cR[a,b]$ for $f$ and $g$ Riemann integrable. We first show this for $f^{2}$.
\begin{proof}
    We show that $f^{2} \in \cR[a,b]$. We have
    \begin{align}
        \abs{f^{2}(x)-f^{2}(y)} = \abs{f(x)+f(y)}\abs{f(x)-f(y)} &\leq 2M \abs{f(x)-f(y)} \notag \\
        \implies \sum_{j} \osc_{I_{j}} \abs{f}^{2} \cdot \abs{I_{j}} &\leq \sum_{j} 2M \cdot \osc_{I_{j}} f \cdot \abs{I_{j}} \notag \\
        U(f^{2},P)-L(f^{2},P) &\leq 2M(U(f,P)-L(f,P)).
    \end{align}
    Since $f$ is Riemann integrable, $U(f,P)-L(f,P)$ can be lowered to less than $\varepsilon > 0$, we can make the left hand term less than $\varepsilon$. Thus, $f^{2} \in \cR[a,b]$.
\end{proof}
Despite this, $\cI(f^{2}) \neq (\cI(f))^{2}$; $\cI$ is not multiplicative.

\item Let us show $f \cdot g \in \cR[a,b]$.
\begin{proof}
    Break down $f \cdot g$ as
    \begin{equation}
        f \cdot g = \frac{1}{4}\left( (f+g)^{2} - (f-g)^{2}\right).
    \end{equation}
    From the previous results, the right hand side is Riemann integrable. Thus, $f \cdot g \in \cR[a,b]$.
\end{proof}

\item If $f(x) \geq 0$ for all $x \in [a,b]$, then $\cI(f) \geq 0$. This result is left as an exercise to the reader.

\item If $f \geq g$, then $\cI(f) \geq \cI(g)$. This result is also left as an exercise to the reader.

\item If $f \in \cR[a,b]$, then $\abs{f} \in \cR[a,b]$. Moreover, $\abs{\cI(f)} \leq \cI(\abs{f})$.
\begin{proof}
    Start with
    \begin{equation}
        \abs{f(x)}-\abs{f(y)} \leq \abs{f(x)-f(y)}.
    \end{equation}
    Therefore, for all $P \in \cP[a,b]$, $\osc_{I_{j}} \abs{f} \leq \osc_{I_{j}} f$ for all valid $j$. Thus,
    \begin{equation}
        U(\abs{f},P) - L(\abs{f},P) \leq U(f,P) - L(f,P)
    \end{equation}
    tells us that $\abs{f}$ is also Riemann integrable. Using the fact that $\cI$ is monotonous,
    \begin{align}
        -\abs{f} \leq f \leq \abs{f} \implies -\int \abs{f} \leq \int f \leq \int \abs{f} \implies \abs{\cI(f)} \leq \cI(\abs{f}).
    \end{align}
\end{proof}

\item We have $\max\{f,g\},\min\{f,g\} \in \cR[a,b]$. The proof of this result is left as an exercise to the reader.

\item If $\frac{1}{g} \in \cB[a,b]$, then $\frac{1}{g} \in \cR[a,b]$. This would also imply that $\frac{f}{g} \in \cR[a,b]$.
\begin{proof}
    Denote $1/\tilde{M} = \sup_{[a,b]} \frac{1}{g}$. Then,
    \begin{equation}
        \abs{\frac{1}{g(x)} - \frac{1}{g(y)}} \leq \frac{1}{\tilde{M}^{2}} \abs{g(x)-g(y)}.
    \end{equation}
    We can then proceed by using the oscillations.
\end{proof}

\item Let $a < c < b$. Then $f|_{[a,c]} \in \cR[a,c]$ and $f|_{[c,b]} \in \cR[c,b]$. Moreover, $\int_{a}^{c} f + \int_{c}^{b} f = \int_{a}^{b} f$.

\begin{proof}
    For $\varepsilon > 0$, there exists $P \in \cP[a,b]$ such that $U(f,P) - L(f,P) < \varepsilon$. Let, without loss of generality, $c \in P$. If not, we could refine $P$ as $P \cup \{c\}$. We then have $P: x_{0} = a < x_{1} < \ldots < x_{m} = c < \ldots < x_{n} = b$. The nodes from $x_{0}$ to $x_{m}$ form a partition $P_{1} \in \cP[a,b]$, and the nodes $x_{m}$ to $x_{n}$ form a partition $P_{2} \in \cP[c,b]$. Thus,
    \begin{align}
        (U(f,P_{1})-L(f,P_{1})) + (U(f,P_{2})-L(f,P_{2})) < \varepsilon.
    \end{align}
    Both of these pairs of terms are non-negative, so each pair individually is less than $\varepsilon$. Thus, $f|_{[a,c]} \in \cR[a,c]$ and $f|_{[c,b]} \in \cR[c,b]$. Now let $\lambda_{1} = \int_{a}^{c} f$ and $\lambda_{2} = \int_{c}^{b} f$. Then,
    \begin{align}
        \int_{a}^{b} f \geq L(f,P) = L(f,P_{1}) + L(f,P_{2}) > U(f,P_{1}) - \varepsilon + U(f,P_{2}) - \varepsilon \geq \lambda_{1} + \lambda_{2} - 2\varepsilon
    \end{align}
    and
    \begin{align}
        \int_{a}^{b} f \leq U(f,P) = U(f,P_{1}) + U(f,P_{2}) < L(f,P_{1}) + \varepsilon + L(f,P_{2}) + \varepsilon \leq \lambda_{1} + \lambda_{2} + 2\varepsilon.
    \end{align}
    Both inequalities imply that $\abs{\int_{a}^{b} f - (\lambda_{1}+\lambda_{2})} \leq 2\varepsilon$.
\end{proof}
\subsection{Results on $f \in \cR[a,b]$}
Assume that, here, $f \in \cR[a,b]$.
\begin{enumerate}
    \item $m(b-a) \leq \int_{a}^{b} f \leq M(b-a)$. This result is left as an exercise to the reader.
    \item If $f \in \cC[a,b]$, then there exists $c \in [a,b]$ such that $f(c) = \frac{1}{b-a} \int_{a}^{b} f$. This is known as the \eax{mean value theorem}.
    \begin{proof}
        Simply start with $m(b-a) \leq \int_{a}^{b} f \leq M(b-a)$, and divide everything by $b-a \neq 0$. There exists $\eta$ and $\zeta$ such that $f(\eta) = m$ and $f(\zeta) = M$, so $f$ takes every value in between.
    \end{proof}
\end{enumerate}

\begin{theorem}
    Let $f:[a,b] \to [c,d]$ and $g:[c,d] \to \R$, and let $f \in \cR[a,b]$ and $g \in \cC[c,d]$. Then $g \circ f \in \cR[a,b]$. Note that for this to be satisfied, $g$ must be continuous on top of Riemann integrable.
\end{theorem}
\begin{proof}
    Clearly, $g \circ f \in \cB[a,b]$. By uniform continuity, for every $\varepsilon > 0$, there exists $\delta > 0$ such that
    \begin{equation}
        \abs{g(x)-g(y)} < \frac{\varepsilon}{2(b-a)} \text{ for all } \abs{x-y} < \delta.
    \end{equation}
    Also, there exists $P \in \cP[a,b]$ such that
    \begin{equation}
        U(f,P) - L(f,P) < \frac{\varepsilon \delta}{4M}
    \end{equation}
    where $M = \sup_{[c,d]} g(y)$. We claim that $U(g \circ f, P) - L(g \circ f, P) < \varepsilon$. Let $n$ be the number of intervals of $P$. Write $J = \{1,2,\ldots,n\} = J_{1} \sqcup J_{2}$, where we define
    \begin{equation*}
        J_{1} = \{j \in J : \osc_{I_{j}}f < \delta \}, \; J_{2} = \{j \in J : \osc_{I_{j}}f \geq \delta\}.
    \end{equation*}
    Now, if $j \in J_{1}$, then 
    \begin{align}
        \abs{f(x)-f(y)} &< \delta \text{ for all } x,y \in I_{j} \\
        \implies \abs{g(f(x)) = g(f(y))} &< \frac{\varepsilon}{2 (b-a)} \text{ for all } x,y \in I_{j} \notag \\
        \implies \sup_{x,y \in I_{j}} \abs{g(f(x))-g(f(y))} = \osc_{I_{j}} g \circ f &\leq \frac{\varepsilon}{2(b-a)} \notag \\
        \implies \sum_{j \in J_{1}} \osc_{I_{j}} g \circ f \cdot \abs{I_{j}} &\leq \frac{\varepsilon}{2(b-a)} \cdot \sum_{j \in J_{1}} \abs{I_{j}} \leq \frac{\varepsilon}{2}.
    \end{align}
    Now, if $j \in J_{2}$, then
    \begin{align}
        \osc_{I_{j}} g \circ f &\leq 2M \\
        \implies \sum_{j \in J_{2}} \osc_{I_{j}} g \circ f \cdot \abs{I_{j}} &\leq 2M \cdot \sum_{j \in J_{2}} \abs{I_{j}} \leq 2M \cdot \sum_{j \in J_{2}} \abs{I_{j}} \osc_{I_{j}} \cdot \frac{1}{\delta} \notag \\
        &\leq \frac{2M}{\delta} \cdot \sum_{j \in J} \abs{I_{J}} \osc_{I_{j}} f = \frac{2M}{\delta} (U(f,P)-L(f,P)) < \frac{2M}{\delta} \cdot \frac{\varepsilon \delta}{4 M} \\
        \implies \sum_{j \in J_{2}} \osc_{I_{j}} g \circ f \cdot \abs{I_{j}} &< \frac{\varepsilon}{2}
    \end{align}
    Combining both inequalities, we have
    \begin{equation}
        U(g \circ f, P) - L(g \circ f, P) = \sum_{j \in J_{1}} \osc_{I_{j}} g \circ f \cdot \abs{I_{j}} + \sum_{j \in J_{2}} \osc_{I_{j}} g \circ f \cdot \abs{I_{j}} < \varepsilon.
    \end{equation}
\end{proof}
\begin{example}
    Let $f \in \cR[a,b]$. From the previous theorem, $e^{f}, \sin f, \cos f \in \cR[a,b]$ and for $f \geq 0$, $f^{\frac{1}{n}} \in \cR[a,b]$.
\end{example}
\begin{theorem}
    Let $f,g \in \cB[a,b]$. If $f(x) = g(x)$ for all $x$ but finitely many, then $f \in \cR[a,b]$ if and only if $g \in \cR[a,b]$. Moreover, in this case, $\int_{a}^{b} f = \int_{a}^{b} g$.
\end{theorem} So, if $f \equiv 0$ except for some finitely many points in $[a,b]$, then $f \in \cR[a,b]$ and $\int_{a}^{b} f = 0$.
\begin{proof}
    Without loss of generality, let $c \in [a,b]$ and $f(x) = g(x)$ for all $x \in [a,b]\backslash \{c\}$, and $f(c) \neq g(c)$. Note that it is enough to prove $\overline{\int} f = \overline{\int} g$ and $\underline{\int} f = \underline{\int} g$. Let $\tilde{M} \geq \sup f, \sup g$. For $\varepsilon > 0$, there exists $P \in \cP[a,b]$ such that
    \begin{equation}
        U(f,P) < \frac{\varepsilon}{2} + \overline{\int} f.
    \end{equation}
    Now set $\delta = \frac{\varepsilon}{8 \tilde{M}}$. Let $\tilde{P} \supset P$ such that $\norm{\tilde{P}} < \delta$. Now $f \equiv g$ except for $x = c$. Let $\{\tilde{I_{j}}\}_{j=1}^{n}$ be the subintervals of $\tilde{P}$. Let $p$ (and possibly $p+1$) be such that $f(x) \neq g(x)$ on $I_{p}$ (and possibly on $I_{p+1})$. Note that
    \begin{align*}
        \abs{\sup_{I_{j}} f - \sup_{I_{j}}} g &= 0 \text{ for all } j \neq p, p+1 \text{ or }\\
        &\leq 2\tilde{M} \text{ for } j = p,p+1.
    \end{align*}
    Thus,
    \begin{align}
        \abs{U(f,\tilde{P})-U(g,\tilde{P})} &\leq \sum_{j=1}^{n} \abs{I_{j}} \cdot \abs{\sup_{I_{j}}f - \sup_{I_{j}} g} = \sum_{j = p,p+1} \abs{I_{j}} \cdot \abs{\sup_{I_{j}}f - \sup_{I_{j}} g} \leq 4\delta \tilde{M} \\
        \implies \abs{U(f,\tilde{P}) - U(g,\tilde{P})} &< \frac{\varepsilon}{2}.
    \end{align}
    Using this, we have
    \begin{align}
        \overline{\int} g &\leq U(g,\tilde{P}) < U(f,\tilde{P}) + \frac{\varepsilon}{2} \leq U(f,P) + \frac{\varepsilon}{2} < \frac{\varepsilon}{2} + \overline{\int} f + \frac{\varepsilon}{2} \notag\\
        \implies \overline{\int} g &< \overline{\int} f + \varepsilon \text{ for all } \varepsilon > 0 \notag\\
        \implies \overline{\int} g &\leq \overline{\int} f.
    \end{align}
    Note that if we switch $f$ and $g$ around, we would get $\overline{\int} f \leq \overline{\int} g$. Thus, we must have
    \begin{equation*}
        \overline{\int} f = \overline{\int} g.
    \end{equation*}
\end{proof}

\section{The Fundamental Theorem of Calculus}
To start off, we will define the set(s) $\cD$ as the set of all differentiable functions, and $\cF(\R)$ is the set of all real valued functions. Recall that we define the integral function as 
\begin{equation}
    \cI : \cR[a,b] \to \cF (\R) \text{ defined as } \cI (f) (x) = \int_{a}^{x}f.
\end{equation}
We will also define differentiation as a function,
\begin{equation}
    \frac{d}{dx} : \cD \to \cF(\R) \text{ defined as } \frac{d}{dx} (f) = \frac{df}{dx}. 
\end{equation}
The fundamental theorem of calculus, roughly, states that both $\frac{d}{dx} \circ \cI$ and $\cI \circ \frac{d}{dx}$ are the identity function. There is a little trouble with this rough statement as the composition here makes not much sense.
\begin{definition}
    Let $S \subseteq \R$, and let $f:S \to \R$ be a function. A differentiable function $F$ is called the \eax{antiderivative} of $f$ if $f(x) = F'(x)$ for all $x \in S$.
\end{definition}
\begin{example}
    We state some antiderivatives here.
    \begin{enumerate}
        \item The antiderivative of $x$ is $\frac{1}{2}x^{2}$.
        \item Polynomials have an antiderivative.
        \item Continuous functions have an antiderivative.
        \item The function $f:\R \to \R$ defined as $f(x) = 0$ if $x \geq 0$ and $f(x) = 1$ if $x < 0$ does not have an antiderivative.
    \end{enumerate}
\end{example}
\begin{theorem}[Darboux.]
    Let $f:(a,b) \to \R$ be differentiable, and let $a < a_{0} < b_{0} < b$. If $f'(a_{0}) < r < f'(b_{0})$, then there exists $c_{0} \in (a_{0},b_{0})$ such that $f'(c_{0}) = r$.    
\end{theorem}
\begin{proof}
    Construct a new function as $g(x) = - f(x) + rx$ for all $x \in (a,b)$. Note that $g:(a,b) \to \R$ is differentiable, and $g'(x) = -f'(x) + r$ for all $x \in (a,b)$. Also, $g'(a_{0}) > 0$ and $g'(b_{0}) < 0$. Now, $g|_{[a_{0},b_{0}]}$ is uniformly continuous. Using the sign of the derivatives, we have
    \begin{align}
        g(a_{0}+h)-g(a_{0}) &> 0 \text{ for some small } h > 0,\\
        g(b_{0}+h)-g(b_{0}) &> 0 \text{ for some small } h < 0.
    \end{align}
    From these two equations, we can see that $g$ attains a maximum at some $c_{0} \in (a_{0},b_{0})$. This implies that $g'(c_{0}) = 0$ and $f'(c_{0}) = r$.
\end{proof}
\textit{January 27th.}
\begin{theorem}[The \eax{first fundamental theorem of calculus}]
    Let $f \in \cR[a,b]$, $F \in \cC[a,b]$, and let $F$ be an antiderivative of $f$ on $(a,b)$, that is, $F'(x) = f(x)$ for all $x \in (a,b)$. Then
    \begin{equation}
        \int_{a}^{b} f = F(b)-F(a).
    \end{equation}
\end{theorem}
\begin{proof}
    Let $P \in \cP[a,b]$ defined as $P:a=x_{0}<x_{1}<\ldots<x_{n} = b$. Now,
    \begin{align}
        F(b) - F(a) = \sum_{j=1}^{n} F(x_{j}) - F(x_{j-1}) \notag.
    \end{align}
    Since $F \in \cC[a,b]$, we have $F|_{[x_{j-1},x_{j}]} \in \cC[x_{j-1},x_{j}] \cap \cD(x_{j-1},x_{j})$. Thus, from the intermediate value theorem, there exists some $\zeta_{j} \in (x_{j-1},x_{j})$ such that
    \begin{align}
        F(x_{j})-F(x_{j-1}) = F'(\zeta_{j}) \cdot (x_{j}-x_{j-1}) = f(\zeta_{j}) \cdot (x_{j}-x_{j-1}).
    \end{align}
    We choose these $\zeta_{j}$'s to be our tag set. Thus, we shall have
    \begin{align}
        F(b)-F(a) &= \sum_{j=1}^{n}F(x_{j})-F(x_{j-1}) = \sum_{j=1}^{n}f(\zeta_{j}) \cdot \abs{I_{j}} \notag \\
        \implies L(f,P) &\leq F(b)-F(a) \leq U(f,P) \text{ for all } P \in \cP[a,b] \notag \\
        \implies F(b)-F(a) &= \int_{a}^{b} f.
    \end{align}
\end{proof}
\begin{remark}
    Note that the first fundamental theorem of calculus implies that $\int_{a}^{b} f$ can be computed simply by finding an antiderivative of $f$. We now ask where the antiderivative is, and even if it exists. The second fundamental theorem of calculus answers this.
\end{remark}
\begin{theorem}[The \eax{second fundamental theorem of calculus}]
    Let $f \in \cR[a,b]$. Define $F:[a,b] \to \R$ as $F(x) = \int_{a}^{x} f(t)dt$ for all $x \in [a,b]$. Then,
    \begin{enumerate}
        \item $F \in \cC[a,b]$,
        \item if $f$ is continuous at $x_{0} \in (a,b)$, then $F$ is differentiable at $x_{0}$ and $F'(x_{0}) = f(x_{0})$,
        \item if $f$ is continuous from the right at $a$, then $F_{+}'(a) = f(a)$.
    \end{enumerate}
\end{theorem}
\begin{corollary}
    Let $f \in \cC[a,b]$. Then
    \begin{equation}
        \frac{d}{dx} \left( \int_{a}^{x} f(t) dt \right) = f(x).
    \end{equation}
\end{corollary}
This is an interesting corollary that comes in handy. We now prove the theorem.
\begin{proof}
    Set $M = \sup_{x \in [a,b]} \abs{f(x)}$. Now,
    \begin{align}
        \abs{F(x)-F(y)} = \abs{\int_{x}^{y} f(t) dt}.
    \end{align}
    Now start with
    \begin{align}
        -M &\leq f(t) \leq M \text{ for all } t \in [a,b] \notag\\
        \implies -M(y-x) &\leq \int_{x}^{y} f(t) dt \leq M(y-x) \notag\\
        \implies \abs{F(x)-F(y)} = \abs{\int_{x}^{y}f(t) dt} &\leq M\abs{x-y} \text{ for all } x,y \in [a,b].
    \end{align}
    Any function that satisfies thie property is a \eax{lipschitz function}. It can be shown that any lipschitz function is continuous. This part of the proof is left as an exercise. The first part is now proved.

    Let $f$ be continuous on some $x_{0} \in (a,b)$. For some $x \neq x_{0}$, we can start with
    \begin{align}
        \frac{F(x)-F(x_{0})}{x-x_{0}} - f(x_{0}) &= \frac{1}{x-x_{0}} \int_{x_{0}}^{x} f(t) dt - \frac{1}{x-x_{0}} \int_{x_{0}}^{x} f(x_{0}) dt = \frac{1}{x-x_{0}} \int_{x_{0}}^{x} (f(t)-f(x_{0}))dt.
    \end{align}
    $f$ is continuous at $x_{0}$, so for $\varepsilon > 0$, there exists $\delta > 0$ such that
    \begin{equation*}
        \abs{f(t)-f(x_{0})} < \varepsilon \text{ for all } \abs{t-x_{0}} < \delta.
    \end{equation*}
    Therefore,
    \begin{align}
        \abs{\frac{F(x)-F(x_{0})}{x-x_{0}} - f(x_{0})} &= \abs{\frac{1}{x-x_{0}} \int_{x_{0}}^{x} (f(t)-f(x_{0}))dt} \leq \frac{1}{\abs{x-x_{0}}} \abs{\int_{x_{0}}^{x} \abs{f(t)-f(x_{0})}dt} \notag \\
        &< \frac{1}{\abs{x-x_{0}}} \abs{\int_{x_{0}}^{x} \varepsilon dt} = \varepsilon \text{ for all } x \in (x_{0}-\delta,x_{0}+\delta) \backslash \{x_{0}\}.
    \end{align}
    This must imply that
    \begin{equation}
        \lim_{x \to x_{0}} \frac{F(x)-F(x_{0})}{x-x_{0}} = f(x_{0}).
    \end{equation}
\end{proof}
Here is an interesting example.
\begin{example}
    Define $f:[0,2] \to \R$ by $f = \chi_{[0,1]}$. Clearly, $f \in \cR[0,2]$. Let $F:[0,2] \to \R$ be defined by $F = \int_{0}^{x} f$. We have
    \begin{align*}
        \text{ for all } x \in [0,1], &\; F(x) = \int_{0}^{x} \chi_{[0,1]} = \int_{0}^{x} 1 = x,\\
        \text{ for all } x \in (1,2], &\; F(x) = \int_{0}^{x} \chi_{[0,1]} = \int_{0}^{1} 1 + \int_{1}^{x} 0 = 1. 
    \end{align*}
    The corollary guarantees that the antiderivative of a continuous function is differentiable; if our function is Riemann integrable but not continuous, the antiderivative may not be differentiable.
\end{example}

\subsection{Some Interesting Methods}
\begin{theorem}[The method of \eax{integration by parts}]
    Let $f,g \in \cD[a,b]$ and $f',g' \in \cR[a,b]$. Then,
    \begin{align}
        \int_{a}^{b} f'g + \int_{a}^{b} fg' = f(b)g(b) - f(a)g(a).
    \end{align}
\end{theorem}
\begin{proof}
    Simply start with $\int_{a}^{b} (fg)'$.
\end{proof}
\begin{theorem}[The method of \eax{change of variable}]
    Let $u \in \cD[a,b]$, $u' \in \cR[a,b]$, and let $f \in \cC(u([a,b]))$. Then,
    \begin{equation}
        \int_{a}^{b} f(u(t)) u'(t) dt = \int_{u(a)}^{u(b)} f(x) dx.
    \end{equation}
\end{theorem}
\begin{proof}
    The proof for a constant function $u$ is trivial. So, assume that $u$ is a non-constant function. Note that $(f \circ u) u'$ in Riemann integrable on $[a,b]$. Define $F:u([a,b]) \to \R$ as
    \begin{equation}
        F(x) = \int_{u(a)}^{x} f(t) dt \text{ for all } t \in u([a,b]).
    \end{equation}
    The second fundamental theorem of calculus tells us that $F' = f$ on $u([a,b])$. Now for $t \in [a,b]$, $(F \circ u)'(t) = F'(u(t)) u'(t)$. By the first fundmental theorem of calculus,
    \begin{align}
        \int_{a}^{b} F'(u(t)) u'(t) dt &= \int_{a}^{b} (F \circ u)' (t) dt \\
        \implies \int_{a}^{b} f(u(t)) u'(t) dt &= F(u(b)) - F(u(a)) = \int_{u(a)}^{u(b)} f(t) dt.
    \end{align}
\end{proof}

\end{enumerate}

\chapter{IMPROPER INTEGRALS}
\textit{February 3rd.}

We first state some `assumptions' on Riemann intgerals, which we now consider to be \eax{proper integrals}.
\begin{enumerate}
    \item The function to be integrated was bounded, that is, $f \in \cB[a,b]$.
    \item The interval on which the function was to be integrated was bounded.
\end{enumerate}

We want to talk about integrals of functions that \textit{don't} follow these assumptions.
\begin{enumerate}
    \item Evaluating $\int_{a}^{b} f$ even if $f$ is not bounded on $[a,b]$.
    \item Evaluating $\int_{a}^{\infty} f$, $\int_{-\infty}^{b} f$, or $\int_{-\infty}^{\infty} f$.
\end{enumerate}

\section{Improper Integrals of Type I}

\begin{definition}[An \eax{improper integral of type I}.]
    Let $f \notin \cR[a,b]$, and $f \in \cR[c,b]$ for all $a < c < b$. If
    \begin{equation}
        \lim_{\varepsilon \to 0^{+}} \int_{a+\varepsilon}^{b} f \; \left( = \int_{a}^{b} f \right)
    \end{equation}
    exists, then we say that the integral $\int_{a}^{b} f$ converges to this value, and diverges otherwise. The convergence is equivalent to saying that $\lim_{c \to a^{+}} \int_{c}^{b} f$ exists.

    Similarly, if $f \notin \cR[a,b]$ and $f \in \cR[a,c]$ for all $a < c < b$, and if
    \begin{equation}
        \lim_{\varepsilon \to 0^{+}} \int_{a}^{b-\varepsilon} f \; \left( = \int_{a}^{b} f \right)
    \end{equation}
    exists, then we say that the integral $\int_{a}^{b} f$ converges to this value, and diverges otherwise. The convergence is equivalent to saying that $\lim_{c \to b^{-}} \int_{a}^{c} f$ exists.

    If $f$ properly diverges at a point $a < c < b$ in $[a,b]$, then we define
    \begin{equation}
        \int_{a}^{b} f = \int_{a}^{c} f + \int_{c}^{b} f
    \end{equation}
    provided that \textit{either} of the right hand side integrals exist.
\end{definition}

\begin{example}
    We wish to compute $\int_{0}^{1} \frac{1}{x^{2}} dx$. This is an improper integral of type I; the function is unbounded at $x = 0$. Therefore, for small $\varepsilon > 0$,
    \begin{equation}
        \int_{\varepsilon}^{1} \frac{1}{x^{2}} dx = \left[ -\frac{1}{x} \right]_{\varepsilon}^{1} = \frac{1}{\varepsilon} - 1.
    \end{equation}
    Taking the limit as $\varepsilon$ tends to zero from the positive side, we see that the limit diverges to positive infinity. The improper integral diverges.
\end{example}

\begin{example}
    We wish to compute $\int_{0}^{1} \frac{1}{\sqrt{x}} dx$. For $\varepsilon > 0$, small,
    \begin{align}
        \int_{\varepsilon}^{1} \frac{1}{\sqrt{x}} dx = \left[ 2\sqrt{x} \right]_{\varepsilon}^{1} = 2-2\sqrt{\varepsilon} \to 2 \text{ as } \varepsilon \to 0^{+}.
    \end{align}
    Thus, $\int_{0}^{1} \frac{1}{\sqrt{x}} dx = 2$.
\end{example}

\begin{example}
    We wish to compute $\int_{0}^{2} \frac{1}{2x-x^{2}} dx$. Let us split this integral as $\int_{0}^{2} f = \int_{0}^{1} + \int_{1}^{2}$. For $\varepsilon > 0$, small,
    \begin{equation}
        \int_{1}^{2-\varepsilon} \frac{1}{x(2-x)}dx = \left[ \frac{1}{2} \ln \left( \frac{x}{2-x} \right) \right]_{1}^{2-\varepsilon} = \frac{1}{2} \ln \left( \frac{2-\varepsilon}{\varepsilon} \right) - \frac{1}{2} \ln 1.
    \end{equation}
    This integral diverges, so the entire integral must diverge.
\end{example}

In general,
\begin{example}
    Let $p > 0$. We wish to evaluate $\int_{0}^{1} \frac{1}{x^{p}} dx$. For $\varepsilon > 0$, small,
    \begin{align}
        \int_{\varepsilon}^{1} \frac{1}{x^{p}} dx = \begin{cases}
            \left[ \frac{x^{1-p}}{1-p} \right]_{\varepsilon}^{1} &\text{ if } p \neq 1, \\
            \left[ \ln x \right]_{\varepsilon}^{1} &\text{ if } p = 1
        \end{cases} = \begin{cases}
            \frac{1}{1-p}(1-\varepsilon^{1-p}) &\text{ if } p \neq 1, \\
            - \ln \varepsilon &\text{ if } p = 1.
        \end{cases}
    \end{align}
    If we apply $\lim_{\varepsilon \to 0^{+}}$, we see that $\int_{0}^{1} \frac{1}{x^{p}}$ converges to $\frac{1}{1-p}$ if $0 < p < 1$, and diverges otherwise.
\end{example}

\subsection{Tests of Convergence}
We now discuss when an improper integral of type I is convergent or not.
\begin{theorem}[The \eax{comparison test I}]
    Let $0 \leq f(x) \leq g(x)$ for all $x \in [a,b)$. Assume that $\int_{a}^{b} g$ and $\int_{a}^{b} g$ are improper integrals solely due to the point $x = b$.
    \begin{enumerate}
        \item If $\int_{a}^{b} g$ converges, then $\int_{a}^{b} f$ converges.
        \item If $\int_{a}^{b} f$ diverges, then $\int_{a}^{b} g$ diverges.
    \end{enumerate}
\end{theorem}
\begin{proof}
    We prove part the first part only. Set $G(x) = \int_{a}^{x} g$ for all $x \in [a,b)$. As $\int_{a}^{b} g$ converges, and $G$ is non-decreasing function, we have
    \begin{equation*}
        \int_{a}^{b} g = \sup \{\int_{a}^{x} g \; | x \in [a,b) \}.
    \end{equation*}
    Now, from the inequality, since the integral function is monotonous,
    \begin{align}
        0 &\leq \int_{a}^{x} f \leq \int_{a}^{x} g \text{ for all } x \in [a,b) \notag \\
        \implies 0 &\leq \sup_{x \in [a,b)} \int_{a}^{x} f \leq \int_{a}^{b} g < \infty \\
        \implies \lim_{c \to b^{-}} \int_{a}^{c} f &< \infty.
    \end{align}
\end{proof}

\begin{example}
    We question whether $\int_{0}^{\frac{\pi}{2}} \frac{\sin x}{x^{p}} dx$ converges for $p > 0$. Firstly, note that
    \begin{align*}
        0 \leq \sin x \leq 1 \implies 0 \leq \frac{\sin x}{x^{p}} \leq \frac{1}{x^{p-1}} \text{ for all } x \in (0, \frac{\pi}{2}].
    \end{align*}
    Note that the integral of the rightmost term converges for $1 < p < 2$. Also, $\int_{0}^{1} \frac{1}{x^{p}} dx$ also converges for $0 < p < 1$. The case for $p = 1$ is also convergent. Hence, $\int_{0}^{\frac{\pi}{2}} \frac{\sin x}{x^{p}}$ converges if $0 < p < 2$.
\end{example}

\begin{theorem}[The \eax{limit comparison test I}]
    Let $f(x), g(x) \geq 0$ for all $x \in [a,b)$. Suppose
    \begin{equation*}
        \lim_{x \to b^{-}} \frac{f(x)}{g(x)} = l \neq 0, \infty.
    \end{equation*}
    Then the improper integrals $\int_{a}^{b} f$ and $\int_{a}^{b} g$ converge, or diverge, together.
\end{theorem}
\begin{proof}
    We know $0 < l < \infty$. Pick $\varepsilon > 0$ such that $l- \varepsilon > 0$. There exists $c \in [a,b)$ such that
    \begin{align}
        \abs{\frac{f(x)}{g(x)} - l} &< \varepsilon \text{ for all } x \in (c,b) \notag \\
        \implies l - \varepsilon < \frac{f(x)}{g(x)} &< l+\varepsilon \text{ for all } x \in (c,b).
    \end{align}
    Therefore, $0 < (l-\varepsilon) g(x) < f(x)$ for all $x \in (c,b)$. By the comparison test - I, if $\int_{a}^{b} f$, that is, $\int_{c}^{b} f$ converges, then $\int_{c}^{b} (l-\varepsilon) g$, that is, $\int_{a}^{b} (l-\varepsilon) g$ converges. This tells us that $\int_{a}^{b} g$ converges. To show that $\int_{a}^{b} g$ converges implies that converge of $\int_{a}^{b} f$ is left as an exercise to the reader.
\end{proof}

\textit{February 6th.}
\begin{definition}
    An improper integral $\int_{a}^{b} f$ is absolutely convergent if the improper integral $\int_{a}^{b} \abs{f}$ converges.
\end{definition}

\begin{theorem}
    The absolute convergence of an improper integral implies the convergence of the improper integral.
\end{theorem}
\begin{proof}
    Let $\int_{a}^{b}f$ be an improper integral at $a$. Now, $-\abs{f(x)} \leq f(x) \leq \abs{f(x)}$ implies that $0 \leq \abs{f(x)} + f(x) \leq 2\abs{f(x)}$ for all $x \in (a,b]$. Therefore, for all $a < c < b$,
    \begin{align}
        0 \leq \int_{c}^{b} (\abs{f(x)}+f(x))dx \leq 2 \int_{c}^{b} \abs{f(x)} dx.
    \end{align}
    If the rightmost integral converges, then by the comparison test, $\int_{a}^{b} \abs{f}+f$ converges. Finally,
    \begin{align}
        \int_{c}^{b} f(x)dx &= \int_{c}^{b} (\abs{f(x)}+f(x)) dx - \int_{c}^{b} \abs{f(x)} dx \notag \\
        \implies \lim_{c \to a^{+}} \int_{c}^{b} f(x)dx &= \int_{a}^{b} (\abs{f(x)}+f(x)) dx - \int_{a}^{b} \abs{f(x)} dx.
    \end{align}
\end{proof}

\section{Improper Integrals of Type II}

\begin{definition}[An \eax{improper integral of type II}.]
    Fix $a \in \R$ and let $f \in \cR[a,r]$ for all $r > a$. If $\lim_{r \to \infty} \int_{a}^{r} f$ exists, then we say that $\int_{a}^{\infty} f$ converges and we write
    \begin{align}
        \int_{a}^{\infty} f = \lim_{r \to \infty} \int_{a}^{r} f.
    \end{align}
    If the limit diverges, then we say that the integral diverges. Similarly, we define
    \begin{align}
        \int_{-\infty}^{b} = \lim_{r \to \infty} \int_{-r}^{a} f
    \end{align}
    provided that the limit exists.
\end{definition}

\begin{definition}
    Let $f \in \cR[a,b]$ for all $a < b \in \R$. If there exists a $c \in \R$ such that $\int_{-\infty}^{c} f$ and $\int_{c}^{\infty} f$ exist, then we say that $\int_{-\infty}^{\infty} f$ exists and define
    \begin{align}
        \int_{-\infty}^{\infty} f= \int_{-\infty}^{c} f + \int_{c}^{\infty} f.
    \end{align}
    Note that the value of the integral, if it exists, is independent of the choice of $c$; this result is left as an exercise to the reader.
\end{definition}

\begin{example}
    We wish to compute $\int_{0}^{\infty} \sin x dx$. Note that, by the fundamental theorem of calculus,
    \begin{align}
        \int_{0}^{r} \sin x dx = [-\cos x]_{0}^{r} = 1 - \cos r.
    \end{align}
    The right hand side does not converge as $r \to \infty$, so we conclude that the integral does not converge.
\end{example}
\begin{example}
    We wish to compute $\int_{-\infty}^{0} e^{-x} dx$. Note that $e^{-x} \in \cR[-r,0]$ for all $r > 0$. Also,
    \begin{align}
        \int_{-r}^{0} e^{-x} dx = [-e^{-x}]_{-r}^{0} = e^{r}-1 \to \infty \text{ as } r \to \infty.
    \end{align}
    Therefore, the integral diverges.
\end{example}
\begin{example}
    We wish to compute $\int_{-\infty}^{\infty} \frac{dx}{1+x^{2}}$. Let us take $c = 0$ to be out `split'; evaluating the integrals, we have
    \begin{align}
        \int_{0}^{\infty} \frac{dx}{1+x^{2}} = \lim_{r \to \infty} \int_{0}^{r} \frac{dx}{1+x^{2}} = \left[ \arctan x \right]_{0}^{r} = \arctan r \to \frac{\pi}{2} \text{ as } r \to \infty,\\
        \int_{-\infty}^{0} \frac{dx}{1+x^{2}} = \lim_{r \to \infty} \int_{-r}^{0} \frac{dx}{1+x^{2}} = \left[ \arctan x \right]_{-r}^{0} = \arctan r \to \frac{\pi}{2} \text{ as } r \to \infty.
    \end{align}
    Thus,
    \begin{align}
        \int_{-\infty}^{\infty} \frac{dx}{1+x^{2}} = \int_{-\infty}^{0} \frac{dx}{1+x^{2}} + \int_{0}^{\infty} \frac{dx}{1+x^{2}} = \frac{\pi}{2} + \frac{\pi}{2} = \pi.
    \end{align}
\end{example}
We say that $f \in \cR[a,\infty)$ if $f \in \cR[a,r]$ for all $r > a$; this is just another notation.

\subsection{Tests of Convergence}
\begin{theorem}[The \eax{comparison test II}]
    Let $a \in \R$ and let $f,g \in \cR[a,\infty)$. Suppose that $0 \leq f(x) \leq g(x)$ for all $x \in [a,\infty)$.
    \begin{enumerate}
        \item If $\int_{a}^{\infty} g$ converges, then $\int_{a}^{\infty} f$ converges.
        \item If $\int_{a}^{\infty} f$ diverges, then $\int_{a}^{\infty} g$ diverges.
    \end{enumerate}
\end{theorem}
\begin{proof}
    For all $t > a$, it follows that
    \begin{align}
        0 \leq \int_{a}^{t} f(x)dx \leq \int_{a}^{t} g(x)dx.
    \end{align}
    Denote the two depicted integrals by $F(t)$ and $G(t)$ respectively, for all $t > a$. The result follows.
\end{proof}
\begin{example}
    We question whether $\int_{a}^{\infty} \frac{dx}{e^{x}+1}$ converges. Note that $\frac{1}{e^{x}+1} \leq e^{-x}$ for all $x \in [a,\infty)$. Evaluting the integral of the right hand side function,
    \begin{align}
        \int_{a}^{\infty} e^{-x}dx = \lim_{r \to \infty} \int_{a}^{r} e^{-x} dx = \lim_{r \to \infty} (e^{-a}-e^{-r}) = e^{-a}.
    \end{align}
    It converges, so our original integral also converges.
\end{example}

\textit{February 10th.}
\begin{theorem}[The \eax{limit comparison test II}]
    Let $f,g \in \cR[a,\infty)$ and suppose $f(x),g(x) \geq 0$ for all $x \in [0,\infty)$. Also suppose
    \begin{equation*}
        \lim_{x \to \infty} \frac{f(x)}{g(x)} > 0.
    \end{equation*}
    Then the imporper integrals $\int_{a}^{\infty} f$ and $\int_{a}^{\infty} g$ converge, or diverge, together.
\end{theorem}
\begin{proof}
    The proof is left as an exercise to the reader.
\end{proof}

\begin{example}
    We wish to test the convergence of $\int_{1}^{\infty} \frac{dx}{x\sqrt{x^{2}+1}}$. Let $f(x) = \frac{1}{x\sqrt{x^{2}+1}}$ and let $g(x) = \frac{1}{x^{2}}$. We see that
    \begin{equation}
        \frac{f(x)}{g(x)} = \frac{1}{\sqrt{1+\frac{1}{x^{2}}}} \to 1 > 0 \text{ as } x \to \infty.
    \end{equation}
    As $\int_{1}^{\infty} \frac{1}{x^{2}} dx$ is convegent, then by the limit comparison test, $\int_{1}^{\infty}\frac{dx}{x\sqrt{x^{2}+1}}$ must also converge.
\end{example}

\begin{theorem}
    Let $f \in \cR[a,\infty)$. If $\int_{a}^{\infty} \abs{f}$ converges, then $\int_{a}^{\infty} f$ also converges. The converse is not true.
\end{theorem}


\chapter{REFINING OF CONVERGENCE}

Recall the following:
\begin{enumerate}
    \item The \eax{Cauchy limit criterion}; $\lim_{x \to a} f(x)$ exists if and only if for all $\varepsilon > 0$, there exists a $\delta > 0$ such that
    \begin{equation}
        \abs{f(x_{1})-f(x_{2})} < \varepsilon \text{ for all } x_{1},x_{2} \in (a-\delta,a+\delta)\backslash \{a\}.
    \end{equation}

    \item We say $\lim_{x \to \infty} f(x) = l$ if for every $\varepsilon > 0$, there exiss $M > 0$ such that
    \begin{equation}
        \abs{f(x)-l} < \varepsilon \text{ for all } x > M.
    \end{equation}

    \item Also, $\lim_{x \to \infty} f(x) = l$ if and only if for every $\varepsilon > 0$, there exists $M > 0$ such that
    \begin{equation}
        \abs{f(x_{1})-f(x_{2})} < \varepsilon \text{ for all } x_{1},x_{2} > M.
    \end{equation}
\end{enumerate}

\begin{theorem}[\eax{Cauchy test for convergence of integrals}]
    Let $f \in \cR[a,\infty)$. Then $\int_{a}^{\infty} f$ converges if and only if for every $\varepsilon > 0$, there exists $M > 0$ such that
    \begin{equation*}
        \abs{\int_{R_{1}}^{R_{2}} f} < \varepsilon \text{ for all } R_{1},R_{2} > M.
    \end{equation*}
\end{theorem}
\begin{proof}
    We can easily see that $\int_{a}^{\infty} f$ converges $\iff$ $\lim_{R \to \infty} \int_{a}^{R} f$ converges $\iff$ for every $\varepsilon > 0$, there exists $M > 0$ such that
    \begin{equation}
        \abs{\int_{a}^{R_{1}} f - \int_{a}^{R_{2}} f} < \varepsilon \text{ for all } R_{1},R_{2} > M.
    \end{equation}
    But the left hand side is just $\int_{R_{1}}^{R_{2}} f$.
\end{proof}

\begin{theorem}
    Let $\int_{a}^{b} f$ be an improper integral at $b$. Then $\int_{a}^{b} f$ exists if and only if for all $\varepsilon > 0$, there exists $\delta > 0$ such that $a < b - \delta$ and
    \begin{equation*}
        \abs{\int_{x_{1}}^{x_{2}} f} < \varepsilon \text{ for all } x_{1},x_{2} \in (b-\delta,b).
    \end{equation*}
\end{theorem}
\begin{proof}
    The proof is left as an exercise to the reader.
\end{proof}

\begin{theorem}[\eax{Absolute convergence test}]
    Let $\varphi \in \cB[a,\infty) \cap \cR[a,\infty)$. If $\int_{a}^{\infty} f$ is absolutely convergent, then $\int_{a}^{\infty} \varphi f$ is also absolutely convergent.
\end{theorem}
\begin{proof}
    Set $M$ to be $\sup_{x \in [a,\infty)} \abs{\varphi(x)}$. Then, we must have $\abs{(\varphi f)(x)} \leq M\abs{f(x)}$ for all $x \in [a,\infty)$. By the limit comparison test, we are done.
\end{proof}

\begin{theorem}[The \eax{first mean value theorem}]
    Let $f,g \in \cR[a,b]$ and suppose that $f$ keeps the same sign over $[a,b]$. Then there exists $\zeta \in [\inf g, \sup g]$ such that
    \begin{equation*}
        \int_{a}^{b} fg = \zeta \int_{a}^{b} f.
    \end{equation*}
\end{theorem}
\begin{remark} Before proving the first mean value theorem, we have a remark.
    \begin{enumerate}
        \item If $g \in \cC[a,b]$, then $\int_{a}^{b} fg = g(c) \int_{a}^{b} f$ for some $c \in [a,b]$.
        \item If $f \equiv 1$, and $g \in \cC[a,b]$, then there exists $c \in [a,b]$ such that
        \begin{equation*}
            g(c) = \frac{1}{b-a} \int_{a}^{b} g.
        \end{equation*}
    \end{enumerate}
\end{remark}
\begin{proof}
    Let $m = \inf_{[a,b]} g$ and let $M = \sup_{[a,b]} g$. Thus, $m \leq g(x) \leq M$ for all $x \in [a,b]$. Without loss of generality, assume that $f > 0$. The inequality implies that
    \begin{align}
        mf(x) \leq f(x) g(x) \leq M f(x) \implies m\int_{a}^{b} f \leq \int_{a}^{b} fg \leq M \int_{a}^{b} f.
    \end{align}
    Thus, there exists a $\zeta \in [m,M]$ such that $\int_{a}^{b} fg = \zeta \int_{a}^{b} f$.
\end{proof}

\begin{example}
    Let $r \in (0,1)$. Then,
    \begin{align}
        \frac{\pi}{6} \leq \int_{0}^{\frac{1}{2}} \frac{dx}{\sqrt{(1-x^{2})(1-rx^{2})}} \leq \frac{\pi}{6} \frac{1}{\sqrt{1-\frac{r}{4}}}.
    \end{align}
    To show this, let $f(x) = \frac{1}{\sqrt{1-x^{2}}}$ and let $g(x) = \frac{1}{\sqrt{1-rx^{2}}}$ for all $x \in [0,\frac{1}{2}]$. Clearly, $f,g \in \cC[0,\frac{1}{2}]$ and $f > 0$. Let us denote $\int_{0}^{\frac{1}{2}} fg$ by $I$. So, by the first mean value theorem, $I = g(c) \int_{0}^{\frac{1}{2}} f = g(c) \frac{\pi}{6}$ for some $c \in [0,\frac{1}{2}]$. For $c \leq \frac{1}{2}$, notice that $c^{2} \leq \frac{1}{4} \implies rc^{2} \leq \frac{r}{4}$ which will give us $g(c) \leq \frac{1}{\sqrt{1-\frac{r}{4}}}$.

    For the left inequality, we observe $0 \leq f \leq fg \implies \frac{\pi}{6} \leq \int_{0}^{\frac{1}{2}} fg = I$.
\end{example}

\begin{appendices}

\titleformat{\chapter}[display]
  {\normalfont\Large\bfseries}
  {\chaptername\ \thechapter}{20pt}{\Huge}

\titlespacing*{\chapter}{0pt}{20pt}{40pt}

\chapter{Appendix}
Extra content goes here.

\printindex

\end{appendices}

\end{document}
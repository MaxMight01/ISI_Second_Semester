\documentclass[15pt,a4paper]{book}

\usepackage{amsmath, amsthm, amssymb} 
\usepackage{graphicx} % For including graphics
\usepackage{hyperref} % For clickable links
\usepackage{bookmark} % Better control over bookmarks
\usepackage{geometry} % Customize page layout
\usepackage{xcolor} % Colors for text and graphics
\usepackage{enumitem} % Customizable lists
\usepackage{fancyhdr} % Header and footer
\usepackage{titlesec} % Custom section/chapter titles
\usepackage[toc,page]{appendix} % For the appendix
\usepackage{longtable} % For tables spanning multiple pages
\usepackage{mathrsfs} % For script fonts in math mode
\usepackage{tocloft} % Custom table of contents
\usepackage{datetime2} % For dates
\usepackage{caption} % For better control over captions
\usepackage{float} % Fine control over figure/table placement
\usepackage{imakeidx} % For index
\usepackage{pgfplots} % For plot

% Custom Theorem Styles
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

\renewcommand{\cftchapfont}{\normalfont} % Remove bold for chapter names
\renewcommand{\cftchappagefont}{\normalfont} % Remove bold for chapter page numbers
\renewcommand{\qedsymbol}{$\blacksquare$}
\newcommand{\eax}[1]{\emph{#1}\index{#1}} % Macro for emphasis and index
\newcommand{\abs}[1]{\left| #1 \right|} % Absolute value
\newcommand{\R}{\mathbb{R}}
\newcommand{\mc}[1]{\mathcal{#1}}


% Custom Notation List Environment
\newlist{notationlist}{description}{1}
\setlist[notationlist]{font=\bfseries,labelsep=1em}

% Geometry Settings
\geometry{
    top=2.5cm,
    bottom=2.5cm,
    left=2.5cm,
    right=2.5cm,
}

% Hyperref Colors
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=cyan,
    citecolor=red
}

\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{#1}}

% Custom Headers
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark} % Chapter name on top left
\fancyhead[R]{\rightmark}  % section name on top right
\fancyfoot[C]{\thepage}

\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Making index
\makeindex[intoc]

% Title Formatting
\titleformat{\chapter}[display]
  {\normalfont\Large\bfseries \centering}
  {\chaptername\ \thechapter}{20pt}{\Huge \centering}

\titlespacing*{\chapter}{0pt}{20pt}{100pt}

\begin{document}

\pagestyle{empty}

\begin{titlepage}
    \begin{center}
    \vspace*{\fill}
    % Title in all caps
    {\Huge \textbf{\MakeUppercase{Introduction to Statistics and Computation with Data}}\par}

    \vspace{0.5cm} % Adjust vertical spacing between title and subtitle
    % Subtitle in normal text, slightly enlarged
    {\Large Rituparna Sen, notes by Ramdas Singh\par}

    \vspace{0.5cm} % Additional spacing before the author
    % Author information
    {\large Second Semester\par}
    \vspace*{\fill}
    \end{center}
\end{titlepage}

\clearpage

\pagenumbering{roman}

\chapter*{List of Symbols}
\begin{notationlist}
    \item $\hat{\theta}$, the estimate of a variable $\theta$.
    \item $\overline{x}$, the mean of the observations $x_{i}$.
    \item $x_{M}$, the mediam of the observations $x_{M}$.
\end{notationlist}

\newpage
\setcounter{tocdepth}{2}
\tableofcontents

\newpage
\pagenumbering{arabic}
\pagestyle{fancy}


%%-------------------------------------------------------------------------------------------------


\chapter{AN INTRODUCTION TO STATISTICS}

\textit{January 2nd.}

Commonly referred to as the science of data, \eax{statistics} involves collecting, summarizing, presenting, and interpreting data. Randomness and variability in data neccessitate the use of statistics. If a process is deterministic, there is no real need of statistics.

Often in probability, we are given the probability of getting heads in a single coin toss and we may be tasked to find the probability of 4 heads appearing in 10 tosses. In contrast, statistics starts with observing 4 heads appearing in 10 tosses, and utilises this data to determine the probability of a head. If we are to determine the price of a house in city, factors to look for may include the city itself, the specific location and area, the kind of house, the square footage, the age of the house, and the change with time. Despite all this, there is still an element of randomness; it is not a true deterministic quantity.

\section{Fundamental Elements of Statistics}
We first discuss some fundamental elements.
\begin{itemize}
    \item An \eax{experimental unit}. It may be a singular item such a coin toss, or a single house as in the previous example(s).
    \item The \eax{population}. The set of all experimental units. We may note that studying all experimental units is a population may not be possible.
    \item A \eax{census} studies all the units in a population.
    \item A \eax{sample} of the population. A subset of the population. It is ideally chosen in a way that represents the entire population. A true representative sample may not always be possible without the the subset being the entire population.
    \item A \eax{variable}. For each experimental unit in the sample, we record the data on several variables. In the case of the prices of houses, the factors discussed are the variables.
    \item \eax{Univariate} and \eax{multivariate} samples. As expected, a univariate sample has only one variable per unit, and a multivariate one has multiple variables per unit. Two variables per unit in the sample is also often referred to as a \eax{bivariate} sample.
\end{itemize}

\section{Types of Statistics and Data}\
\subsection{Descriptive Statistics}
Often, in statistics, we use pictures, tables, and summary numbers to describe the data. R Studio (or just R) may be used to handle descriptive statistics.

\subsection{Inferential Statistics}
Here, we make statements about the population based on our sample observations. In the case of coin tossing, let us look at the population of infinite coin tosses, where the probability of a heads is an unknown $p$. A census of this population is not possible, so we may take a sample of 10 tosses. Suppose we get $X$ heads in this sample. We know that $X$ follows a binomial distribution as $X \sim \text{Bin}(10,p)$. Here, we describe a new varaible called the \eax{estimate}, $\hat{p}$. In this case, we find that $\hat{p} = X/10$. This is how we work in statistics; we deal with an unknown variable of the population, say $\theta$, by looking at a sample and describing an estimate $\hat{\theta}$.

We may also be tasked to find the \eax{measure of reliability}; how reliable our estimate is. One such measure may be $\abs{\hat{\theta}-\theta}<\delta$ where we target to make $\delta$ as small as possible.

\begin{example}
    Suppose 1000 cola consumers participate in a blind taste test among 2 brands, $A$ and $B$, and are asked their preference. To know which kind is preferred universally, let us begin by asking the following:
    \begin{itemize}
        \item Describing the population. In this case, it is all the cola consumers.
        \item Describing the sample. In this case, it is our chosen 1000 cola consumers.
        \item The variable of interest. Whether people prefer brand $A$ or brand $B$.
        \item Our inference. The preference in the sample is extended to all the cola consumers.
    \end{itemize}
\end{example}

\subsection{Type of Data}
\eax{Qualitative data}, or categorical or nominal or ordinal data, is data with no numerical value representation of it. In reference to the previous example, preference between $A$ and $B$ is a qualitative piece of data. Other such examples include choice of elective courses of a student, the gender of a person, a preference of a cricket team, etc..

\eax{Quantitative data} on the other hand has a numerical value which interests us in statistics. Examples include the age of a person, the semestral marks of a student, the salary of a worker, the cost of books, etc.. Quantitative data is also divided into two parts, discrete and continuous.

\section{Collecting Data}
\textit{January 7th.}

To collect data to perform statistics on, one may choose of the following ways to do so; a most basic source for sampling is a \eax{published source}. In a \eax{designed experiment}, we select experimental units and administer some treatment on each one. In the medical field, these medical experiments are called clinical trials. An \eax{observational study} may also be conducted.

\subsection{Sampling}

Two kinds of simple random sampling exist; one is \eax{simple random sampling without replacement} (SRSWOR), and the other is \eax{simple random sampling with replacement} (SRSWR). Here, the experimental units are chosen sequentially at random with or without replacement. In \eax{cluster sampling}, the population is divided into smaller groups known as clusters. Experimental units are then randomly selected among these clusters to form a sample. In \eax{convenience sampling}, which is a non-probability sampling, the sample is drawn from that part of the population which is close to hand.

\subsection{Sources of Error due to Flawed Sampling}

A major source of error is \eax{selection bias}; some parts of the population are deliberately left out when choosing the sample. It is an error of bias and not of randomness. For example, online surveys leave out people without access to internet. While this may be at fault of the person sampling the population, a \eax{non-response bias} occurs when the population does not respond. A \eax{reponse bias} also exists where the population does not reflect the true value. An error is noting down values or measuring samples may also occure, known as a \eax{measurement error}.

\chapter{REPRESENTING QUANTITATIVE DATA}
The most one can possible do with qualitative data is to pictorially represent it via tables and charts.\\
\textit{January 9th.}

For qualitative data, frequency tables, bar charts, pie charts, and ogives are the most approprite way to pictorially represent them. Quantitative data, on the other hand, have more variety in terms in descriptive statistics. They can be represented in graphs such as a dot plot, stem and leaf plot, histogram, adn even a box and whisker plot.

Plots can also be categorized as skewed and symmetric. A \eax{symmetric plot} is (roughly) the same as its image under reflection about some vertical line. We typically look for symmetry of the population from which the data is a sample. A \eax{skewed plot} is one where a peak in the plot occurs. A peak towards higher values is termed a left skewed plot, while a peak towards lower values is termd a right skewed plot. We can also have a \eax{bimodal distribution} where 2 peaks occur, or even a \eax{multimodal distribution}. More peaks suggests a mixture in the population.

Another thing to look out for are \eax{outliers}. These are a few data points that are very different from the rest of the data. When such an outlier occurs, we are generally provoked to investigate it. A reason for an outlier could be a mistake in recording of data, which can be removed by fixing it. Another possible reason for a outlier is that the data point(s) come from a different distribution. In such a case, it is best to drop such outliers. Outliers may also occur purely due to the population being highly skewed; in this case, such outliers are expected by one.

\section{Graphical Measures}
A \eax{stem and leaf plot}. It is typically used when there are too many data points to draw a meaningful dot plot. It also has the added advantage of no loss of data.
\begin{table}[htbp]
\centering
\caption{Key: $1 | 1= 11$}
\begin{tabular}{r|l@{\hspace{4 pt}}l@{\hspace{4 pt}}l@{\hspace{4 pt}}l@{\hspace{4 pt}}l@{\hspace{4 pt}}l@{\hspace{4 pt}}l@{\hspace{4 pt}}l@{\hspace{4 pt}}l@{\hspace{4 pt}}}
Stem & \multicolumn{8}{l}{ Leaf}\\ \hline
1 & 3 \\
2 & 2 & 4 & 8 & 9 \\
3 & 1 & 2 & 6 & 6 & 7 & 8 \\
4 & 3 & 7 \\
5 & 2
\end{tabular}
\end{table}
One may even look at it as a horizontal histogram, with the number of values per row representing the `height' of the bars.

A \eax{histogram}. For the same data as the previous example, we use bars instead to categorize classes. However, their is a loss of individual data points here.
\begin{center}
\begin{tikzpicture}
\begin{axis}[ybar interval, ymax=10,ymin=0, minor y tick num = 3]
\addplot coordinates { (10, 1) (20, 4) (30, 6) (40, 2) (50, 1) (60, 0)};
\end{axis}
\end{tikzpicture}\\
A histogram.
\end{center}
A general rule of thumb exists for determining the number of classes. When there are less than 25 observations, we choose 5--6 classes; for 25 to 50 observations, 7--14 classes are enough. For more than 50 observations, one may even choose to use about 15--20 classes. Another thing to note about the histogram is that the area under the curve for a particular region represents the proportion of that region in the sample

A \eax{box and whisker plot}. Again using the same data, a box and whisker plot utilises other aspects of the data such as the maximum value, the minimum value, the median value, the first quartile end value, and the third quartile end value. In our case, these are 52, 12, 24, 28, and 38 respectively (\textit{A box and whisker plot is to be added here later}).

A \eax{scatter plot}. The plots discussed before were for univariate data. For bivariate data, a scatter plot is helpful. Here, we plot one variable against the other by representing them as 2-dimensional points. We also discuss the linear relationship in this case.

\section{Numerical Measures}
We first discuss some central values.
\begin{itemize}
    \item The \eax{mean}. It is the average value (the arithmetic mean) of the sample.
    \item The \eax{median}. It is that value the splits the data in half; half the data points are below this value, while the other half are above it.
    \item The \eax{mode}. It is that value which occurs with the highest frequency. Often, for larger samples, a modal class is more meaningful.
\end{itemize}
Note that the mean and median do not make sense for qualitative data. In contrast to this, the mode can be used for both qualitative and quantitative data. The median is sometimes used in qualitative data when it is ordinal.

\begin{example}
    For a set of data points $x_{1}, \ldots, x_{n}$, the mean is defined as $\overline{x} = \left(\sum x_{i}\right)/n$. Show that, for $a = \overline{x}$, the sum of squared deviations of the data points from the value $a$ is minimized, that is, the value $\sum (x_{i} - a)^{2}$ is minimized.
\end{example}
\begin{proof}
    We have
    \begin{align*}
        \sum (x_{i}-a)^{2} &= \sum (x_{i} - \overline{x} + \overline{x} - a)^{2} = \sum (x_{i}-\overline{x})^{2} + \sum (\overline{x}-a)^{2} + 2 \sum (x_{i}-\overline{x})(\overline{x}-a) \\
        &= \sum (x_{i}-\overline{x})^{2} + n(\overline{x}-a)^{2} + 2(\overline{x}-a) \sum (x_{i}-\overline{x}) \\
        &= \sum (x_{i}-\overline{x})^{2} + n(\overline{x}-a)^{2}.
    \end{align*}
    Now $(\overline{x}-a)^{2} \geq 0$; it is 0 if and only if $a = \overline{x}$.
\end{proof}
\textit{January 16th.}\\ \\
We also have another result that says that $\sum \abs{x_{i}-a}$ is minimized when the value of $a = \text{median}(x_{1}, \ldots, x_{n})$.

\subsection{Variability or Spread}
We also are interested in the \eax{variability} or the \eax{spread}; how far the observations or data points are from each other or from the centre.
\begin{itemize}
    \item One is such measure is the \eax{range} defined as $\max - \min$. The range is a simple and intuitive measure of spread. Between different samples from the same population, the value of the range can be very different. It depends on only two values.
    \item Another measure if the \eax{variance}. For $n$ $x_{i}$ observations, we have
    \begin{equation}
        \sigma^{2} = \frac{1}{n-1} \sum_{i=1}^{n} (x_{i}-\overline{x})^{2}
    \end{equation}
    as the variance; it is the average squared distance of eah point from the centre. Dividing by $n-1$ makes the measure `good' as it is unbiased for the population variance.
    \item If we define $x_{M}$ to be the median of the $x_{i}$'s, we can define another measure: \eax{MAD from the median}.
    \begin{equation}
        \text{MAD} = \frac{1}{n} \sum_{i=1}^{n} \abs{x_{i}-x_{M}}.
    \end{equation}
    MAD is short for \eax{mean absolute deviation}.
    \item The \eax{standard deviation} may be defined as the square root of the variance.
    \item The \eax{interquartile range} or IQR. It is a robust measure; applicable if there are a few very high or very low values. It is defined as
    \begin{equation}
        \text{IQR} = Q_{3} - Q_{1}
    \end{equation}
    where $Q_{3}$ is the third quartile, the value for which 75\% of the data resides below it, and $Q_{1}$ is the first quartile, the value for which 25\% of the data resides below it.
\end{itemize}
\begin{example}
    Let us work with the following dataset---
    \begin{equation}
        40, 60, 65, 65, 65, 68, 68, 70, 70, 70, 70, 70, 70, 74, 75, 75, 90, 95 \notag
    \end{equation}
    For this dataset, the median is the $\frac{1}{2}(n+1)$th observation, or the 9.5th observation: $70 + 0.5(70-70) = 0$.

    $Q_{1}$ will be the $\frac{1}{4}(n+1)$th observation, or the $4.75$th observation: $65+0.75(65-65) = 65$.

    $Q_{3}$ will be the $\frac{3}{4}(n+1)$th observation, or the $14.25$th observation: $74+0.25(75-74) = 74.25$.
\end{example}

\subsubsection{The Chebyshev Inequality}
The \eax{Chebyshev inequality} can be summarised as
\begin{equation}
    P\left( \abs{\frac{X-\mu}{\sigma}} \right) \leq \frac{1}{k^{2}}
\end{equation}
where $\mu$ is the population mean and $\sigma$ is the population standard deviation. Along with this, we also adopt the convention $\overline{X}$ for the sample mean, and $s$ for the sample standard deviation. We can also infer that 2 standard deviations worth of values around the mean contain, at the very least, three-fourths of the values.
\begin{equation}
    P(\mu-2\sigma < X < \mu+2\sigma) \geq \frac{3}{4}.
\end{equation}
Note that this is true for all distributions. Similarly, we have $P(\mu-3\sigma < X < \mu+3\sigma) \geq \frac{8}{9}$. If we have $\overline{X}$ and $s$, then we can say that $\frac{8}{9}$ths of the population values will lie between $\overline{X}-3s$ and $\overline{X}+3s$, approximately. In practice, the coverage is more. For example, if have the normal distribution, 95\% of the values will lie in between $\mu \pm 2\sigma$. Chebyshev guarantees that 75\% of the values will lie here for any distribution.

\subsection{Measures of Relative Standing}
These measure look at the `position' of a particular value relative to other, or in comparison to others.
\begin{itemize}
    \item A \eax{rank} is simply ordering of the population, and numbering them in order. The number assigned is the rank.
    \item A \eax{percentile} or \eax{quartile} also exists; it is defined as
    \begin{equation}
        \text{Quartile of value } a = \frac{\#\{x_{i} \leq a\}}{n}.
    \end{equation}
    \item The $\eax{z-score}$ measures how many standard deviations above the mean is the value $a$---
    \begin{equation}
        \text{z-score of } a = \frac{a-\overline{x}}{s}.
    \end{equation}
\end{itemize}

\subsubsection{Detecting Outliers}
The z-score is helpful it detecting outliers; if the absolute value of the z-score of a value $a$ is above 3, there is a high likelihood it is an outlier.

For a boxplot, a good detection system is to check for those values greater than $Q_{3} + 1.5\text{IQR}$ or less than $Q_{1} - 1.5\text{IQR}$.

\chapter{PROBABILITY}
\textit{January 23rd.}

We first discuss the \eax{simple random sampling.} From a set of $N$ elements, a subset of size $n$ is selected such that each subset of size $n$ has equal probability of being the chosen subset. With replacement, this probability is $\frac{1}{N^{n}}$, and without replacement, this probability is $\frac{1}{\binom{N}{n}}$. In practice, this is done iteratively. There are ways to achieve such a sampling; some of these include physically mixing up and making a draw, using a generator, random number tables, or software.

\section{Probabilistic Terms}

\subsection{Random Variables}
For a probability space $(\Omega, \mathcal{F}, P)$, a \eax{random variable} is simply a function $X: \Omega \to \mathbb{R}$. For a given subset $A \subseteq \R$, the probability $P(X \in A)$ is defined as $P(X \in A) = P(X^{-1}(A))$.

We also define the \eax{cumulative distribution function} of $X$ as
\begin{equation}
    F_{X}(a) = P(X \leq a) = P(X \in (-\infty,a]).
\end{equation}
If the random variable is discrete, that is, it takes countably many values, then a \eax{probability mass function} can be defined as $p_{X}(x_{i}) = P(X = x_{i})$. If the random variable is continuous, that is, it takes all values in an interval, then a \eax{probability density function} is defined as $\int_{a}^{b} f_{X}(x)dx = F_{X}(b)-F_{X}(a)$.

\subsection{Mean and Variance}
The mean of a random variable is defined as
\begin{equation}
    \mu = EX = \begin{cases}
        \int_{-\infty}^{\infty} x f_{X}(x) dx &\text{ if $X$ is continuous,}\\
        \sum_{i} x_{i} p_{X}(x_{i}) &\text{ if $X$ is discrete.}
    \end{cases}
\end{equation}
The variance of a random variable is defined as
\begin{equation}
    \sigma^{2} = E[(X-\mu)^{2}] = E[X^{2}] - \mu^{2} = \begin{cases}
        \int_{-\infty}^{\infty} (x-\mu)^{2} f_{X}(x) dx &\text{ if $X$ is continuous,}\\
        \sum_{i} (x_{i}-\mu)^{2} p_{X}(x_{i}) &\text{ if $X$ is discrete.}
    \end{cases}
\end{equation}

\section{Distributions}
\subsection{Discrete Distributions}
\begin{itemize}
    \item \eax{Binomial distribution}. It consists of $n$ trials, all independent, which result in outcome $0$ or $1$. The probability of success in each trial is the same, $p$. Here, $X$ is the number of successes.
    \begin{equation*}
        p_{X}(k) = \binom{n}{k} p^{k}(1-p)^{n-k}, \; EX = np, \; \text{Var}X = np(1-p).
    \end{equation*}
    \item \eax{Multinomial distribution}. The random variable is a vector from $\Omega \to \R^{k}$. There are $n$ trials, all independent, with $k$ possible outcomes in each trial. Each outcome as probability $p_{i}$, with $\sum_{i=1}^{k} p_{i} = 1$. The random variable is written as $X = \begin{pmatrix}
        X_{1} & \ldots & X_{k}
    \end{pmatrix}$, where $X_{i}$ is the number of times outcome $i$ is observed.
    \item \eax{Geometric distribution}. A trial is conducted, independently, until a success instead of a failure is observed. $X$ is the number of such trials required.
    \begin{equation*}
        p_{X}(k) = p \cdot (1-p)^{k-1}.
    \end{equation*}
    \item \eax{Poisson distribution}. The random variable here has the probability mass function defined as
    \begin{equation*}
        p_{X}(k) = e^{-\lambda} \frac{\lambda^{k}}{k!}.
    \end{equation*}
    \item \eax{Hypergeomtric distribution}. $N$ objects exist, with $M$ of the marked. $n$ are sampled, and $X$ is defined as the number of marked ones picked. The probability is given by
    \begin{equation*}
        p_{X}(k) = \frac{\binom{M}{k} \binom{N-M}{n-k}}{\binom{N}{n}}.
    \end{equation*}
\end{itemize}
\subsection{Continuous Distributions}
We shall define the probability mass functions here.
\begin{itemize}
    \item \eax{Uniform distribution}. It has a finite support only. It is given by
    \begin{equation*}
        f_{X}(x) = \begin{cases}
            \dfrac{1}{b-a} &\text{ if } a<x<b, \\
            0 &\text{ if otherwise.}
        \end{cases}
    \end{equation*}
    \item \eax{Beta distribution}. It also have a finite support.
    \begin{equation*}
        f_{X}(x) = \begin{cases}
            \dfrac{x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha,\beta)} &\text{ if } 0 < x < 1, \\
            0 &\text{ if otherwise.}
        \end{cases}
    \end{equation*}
    \item \eax{Exponential distribution}. It has a `rate' denoted by $\lambda$,and a support $\R^{+}$, with proability density function
    \begin{equation*}
        f_{X}(x) = \begin{cases}
            \lambda e^{-\lambda x}  &\text{ if } x > 0,\\
            0 &\text{ if otherwise}.
        \end{cases}
    \end{equation*}
    \item \eax{Gamma distribution}. Takes two parameters $\lambda$ and $\alpha$, with support of $\R^{+}$, with its funciton defined as
    \begin{equation*}
        f_{X}(x) = \begin{cases}
            \dfrac{e^{-\lambda x} x^{\alpha-1}\lambda^{\alpha}}{\Gamma (\alpha)} &\text{ if } x > 0,\\
            0 &\text{ if otherwise}.
        \end{cases}
    \end{equation*}
    \item \eax{Normal distribution}. Takes two parameters $\mu$ and $\sigma$, which are the mean and the standard deviation respectively. It is defined as
    \begin{equation*}
        f_{X}(x) = \frac{1}{\sqrt{2\pi} \sigma} e^{\dfrac{1}{2\sigma^{2}} (x-\mu)^{2}}
    \end{equation*}
\end{itemize}

\begin{appendices}

\titleformat{\chapter}[display]
  {\normalfont\Large\bfseries}
  {\chaptername\ \thechapter}{20pt}{\Huge}

\titlespacing*{\chapter}{0pt}{20pt}{40pt}

\chapter{Appendix}
Extra content goes here.

\printindex

\end{appendices}

\end{document}